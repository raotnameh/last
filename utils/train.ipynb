{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim \n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total speakers: 585\n",
      "Total samples: 24473, Total speakers: 585\n"
     ]
    }
   ],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        input_manifest = \"/raid/home/rajivratn/hemant_rajivratn/librispeech/data/manifest/train-clean-100.tsv\"\n",
    "\n",
    "        # Read the first line to get the root directory\n",
    "        with open(input_manifest, \"r\") as infile:\n",
    "            root_dir = infile.readline().strip()  # First line is the root directory\n",
    "\n",
    "        # Define valid duration range\n",
    "        min_duration = 32000  # 2 seconds\n",
    "        max_duration = 250000  # 15.625 seconds\n",
    "\n",
    "        # Dictionary to store filtered samples per speaker\n",
    "        filtered_samples_by_speaker = {}\n",
    "\n",
    "        with open(input_manifest, \"r\") as infile:\n",
    "            infile.readline()  # Skip header (already read root_dir)\n",
    "            for line in infile:\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                if len(parts) != 2:\n",
    "                    continue\n",
    "                file_name, duration = parts\n",
    "                duration = int(duration)\n",
    "\n",
    "                if min_duration <= duration <= max_duration:\n",
    "                    full_path = os.path.join(root_dir, file_name)\n",
    "                    speaker_id = file_name.split(\"_\")[1]  # Extract speaker ID\n",
    "                    \n",
    "                    if speaker_id not in filtered_samples_by_speaker:\n",
    "                        filtered_samples_by_speaker[speaker_id] = []\n",
    "                    \n",
    "                    filtered_samples_by_speaker[speaker_id].append((full_path, duration))\n",
    "\n",
    "        self.diff_speakers = len(filtered_samples_by_speaker)\n",
    "        print(f\"Total speakers: {self.diff_speakers}\")\n",
    "        # a tuple with path, speaker, duration\n",
    "        filtered_samples = []\n",
    "        count = 0\n",
    "        for k in filtered_samples_by_speaker:\n",
    "            count += 1\n",
    "            for i in filtered_samples_by_speaker[k]:\n",
    "                filtered_samples.append((i[0], count, i[1]))\n",
    "            #     break\n",
    "            # if len(filtered_samples) == 40: \n",
    "            # break\n",
    "            \n",
    "        print(f\"Total samples: {len(filtered_samples)}, Total speakers: {count}\")\n",
    "        # Sort by duration\n",
    "        filtered_samples.sort(key=lambda x: x[-1])\n",
    "\n",
    "        self.dataset = filtered_samples\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, speaker, duration = self.dataset[idx]\n",
    "        waveform, sample_rate = torchaudio.load(path)\n",
    "        assert sample_rate == 16000, \"Sampling rate must be 16000\"\n",
    "        return waveform, speaker, duration\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "dataset = AudioDataset()\n",
    "\n",
    "# create a collate function to truncate the audio files to minimum length\n",
    "def collate_fn(batches):\n",
    "    min_dur = min([batch[2] for batch in batches])\n",
    "    batch = [batch[0][:, :min_dur] for batch in batches]\n",
    "    batch = torch.stack(batch)\n",
    "    return batch.squeeze(1), [batch[1] for batch in batches]\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=1, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/site-packages/torch/utils/_contextlib.py:125: UserWarning: Decorating classes is deprecated and will be disabled in future versions. You should only decorate functions or methods. To preserve the current behavior of class decoration, you can directly decorate the `__init__` method and nothing else.\n",
      "  warnings.warn(\"Decorating classes is deprecated and will be disabled in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports are successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: ' ', 2: \"'\", 3: 'A', 4: 'B', 5: 'C', 6: 'D', 7: 'E', 8: 'F', 9: 'G', 10: 'H', 11: 'I', 12: 'J', 13: 'K', 14: 'L', 15: 'M', 16: 'N', 17: 'O', 18: 'P', 19: 'Q', 20: 'R', 21: 'S', 22: 'T', 23: 'U', 24: 'V', 25: 'W', 26: 'X', 27: 'Y', 28: 'Z', 29: '<sil>', 30: '<bos>', 31: '<eos>'}\n",
      "Paraeters of spk_embed: 0.44928\n",
      "Paraeters of downsampling: 1.771008\n",
      "Paraeters of upsampling: 1.179904\n",
      "Paraeters of decoder: 7.478272\n",
      "Models are initialized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import models\n",
    "from encoder import Encoder, Downsampling\n",
    "from vocab import FrozenVocabulary, get_closest_vocab, merge_similar_indices\n",
    "from decoder import Upsampling, Decoder, calculate_params\n",
    "from codec import Codec\n",
    "\n",
    "print(\"All imports are successful\")\n",
    "\n",
    "class Spk_Embed(nn.Module):\n",
    "    def __init__(self, num_speakers=100, spk_embed_dim=256):\n",
    "        super(Spk_Embed, self).__init__()\n",
    "        self.spk_embed = nn.Embedding(num_speakers, spk_embed_dim)\n",
    "        \n",
    "    def forward(self, speaker):\n",
    "        return self.spk_embed(speaker)\n",
    "    \n",
    "# params\n",
    "hidden_dim = 256\n",
    "spk_embed_dim = 768\n",
    "num_speakers = dataset.diff_speakers\n",
    "\n",
    "# models \n",
    "spk_embed = Spk_Embed(num_speakers=num_speakers, spk_embed_dim=spk_embed_dim)\n",
    "encoder = Encoder() # frozen\n",
    "downsampling = Downsampling()\n",
    "vocab = FrozenVocabulary(path=\"vocab.pth\") # frozen\n",
    "upsampling = Upsampling(inp_dim=int(768+spk_embed_dim), hidden_dim=hidden_dim)\n",
    "decoder = Decoder(hidden_dim=hidden_dim, out_dim=1024, num_blocks=5, kernel_size=11)\n",
    "codec = Codec() # frozen\n",
    "vocab_embeddings, char_to_idx, idx_to_char = vocab.embeddings, vocab.char_to_idx, vocab.idx_to_char\n",
    "\n",
    "print(idx_to_char)\n",
    "print(f\"Paraeters of spk_embed: {calculate_params(spk_embed)}\")\n",
    "print(f\"Paraeters of downsampling: {calculate_params(downsampling)}\")\n",
    "print(f\"Paraeters of upsampling: {calculate_params(upsampling)}\")\n",
    "print(f\"Paraeters of decoder: {calculate_params(decoder)}\")\n",
    "\n",
    "print(\"Models are initialized\")\n",
    "\n",
    "\n",
    "# Set the models to gpu\n",
    "device = torch.device(\"cuda\")\n",
    "encoder = encoder.to(device)\n",
    "downsampling = downsampling.to(device)\n",
    "vocab_embeddings = vocab_embeddings.to(device)\n",
    "decoder = decoder.to(device)\n",
    "upsampling = upsampling.to(device)\n",
    "codec.model = codec.model.to(device)\n",
    "spk_embed = spk_embed.to(device)\n",
    "\n",
    "# freeze the encoder, and codec\n",
    "for param in codec.model.parameters():\n",
    "    param.requires_grad = False   \n",
    "vocab_embeddings.requires_grad = False\n",
    "\n",
    "# Training loop\n",
    "downsampling.train()\n",
    "decoder.train()\n",
    "upsampling.train()\n",
    "codec.model.eval()\n",
    "spk_embed.train()\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the models to training mode\n",
    "encoder.train()\n",
    "for param in encoder.named_parameters():\n",
    "    param[1].requires_grad = False\n",
    "    continue\n",
    "    if \"model.encoder.layers.8\" in param[0] or \"model.encoder.layers.11\" in param[0]:\n",
    "        param[1].requires_grad = True\n",
    "    else:\n",
    "        param[1].requires_grad = False\n",
    "        \n",
    "optimizer = optim.Adam(\n",
    "    list(downsampling.parameters()) + list(decoder.parameters()) + list(upsampling.parameters()) + list(spk_embed.parameters()),\n",
    "    # list(downsampling.parameters()) + list(decoder.parameters()) + list(upsampling.parameters()) + list(encoder.parameters()) + list(spk_embed.parameters()),\n",
    "    lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HubertModel(\n",
       "  (feature_extractor): HubertFeatureEncoder(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): HubertGroupNormConvLayer(\n",
       "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "        (activation): GELUActivation()\n",
       "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (1-4): 4 x HubertNoLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (5-6): 2 x HubertNoLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feature_projection): HubertFeatureProjection(\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): HubertEncoder(\n",
       "    (pos_conv_embed): HubertPositionalConvEmbedding(\n",
       "      (conv): ParametrizedConv1d(\n",
       "        768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "        (parametrizations): ModuleDict(\n",
       "          (weight): ParametrizationList(\n",
       "            (0): _WeightNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (padding): HubertSamePadLayer()\n",
       "      (activation): GELUActivation()\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x HubertEncoderLayer(\n",
       "        (attention): HubertAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): HubertFeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1097e-03,  1.0716e-03,  8.7021e-04,  ...,  7.2552e-04,\n",
       "           2.0577e-03,  1.5775e-03],\n",
       "         [ 1.2447e-03,  1.2546e-03,  1.0578e-03,  ...,  7.4357e-04,\n",
       "           2.1386e-03,  1.7433e-03],\n",
       "         [ 1.2679e-03,  1.2649e-03,  1.0902e-03,  ...,  7.2007e-04,\n",
       "           2.1590e-03,  1.7740e-03],\n",
       "         ...,\n",
       "         [ 3.4858e-02,  2.0660e-02,  2.3154e-02,  ...,  2.3416e-02,\n",
       "           3.1290e-02,  7.9780e-03],\n",
       "         [ 1.3558e-03,  1.3255e-03,  1.2078e-03,  ...,  7.9715e-04,\n",
       "           2.1935e-03,  1.8330e-03],\n",
       "         [ 1.1462e-03,  1.2029e-03,  8.8880e-04,  ...,  5.9375e-04,\n",
       "           2.0590e-03,  1.6928e-03]],\n",
       "\n",
       "        [[ 1.0257e-03,  1.1311e-03,  7.5927e-04,  ...,  6.2689e-04,\n",
       "           1.6387e-03,  2.7738e-03],\n",
       "         [ 1.2818e-03,  1.2915e-03,  1.0284e-03,  ...,  8.5428e-04,\n",
       "           1.8988e-03,  2.9862e-03],\n",
       "         [ 1.2790e-03,  1.3763e-03,  1.0400e-03,  ...,  8.1125e-04,\n",
       "           1.8305e-03,  2.9647e-03],\n",
       "         ...,\n",
       "         [ 8.0596e-03,  2.2083e-02,  2.3952e-02,  ...,  5.1764e-03,\n",
       "           1.3401e-02, -4.3286e-03],\n",
       "         [ 1.4533e-03,  1.4481e-03,  1.1590e-03,  ...,  8.3318e-04,\n",
       "           1.9794e-03,  2.9929e-03],\n",
       "         [ 1.1132e-03,  1.2081e-03,  7.8658e-04,  ...,  8.2065e-04,\n",
       "           1.7742e-03,  2.8540e-03]],\n",
       "\n",
       "        [[ 1.2766e-03,  1.2391e-03,  1.3481e-03,  ...,  1.2036e-03,\n",
       "           1.2436e-03,  9.3320e-04],\n",
       "         [ 1.3522e-03,  1.3186e-03,  1.4097e-03,  ...,  1.2665e-03,\n",
       "           1.1884e-03,  8.9898e-04],\n",
       "         [ 1.3383e-03,  1.3329e-03,  1.4604e-03,  ...,  1.3303e-03,\n",
       "           1.2571e-03,  9.7448e-04],\n",
       "         ...,\n",
       "         [-7.9277e-03,  5.3923e-03, -6.7055e-03,  ...,  1.0930e-02,\n",
       "           1.1979e-02,  1.1147e-02],\n",
       "         [ 1.4513e-03,  1.4401e-03,  1.5685e-03,  ...,  1.3485e-03,\n",
       "           1.3202e-03,  1.0598e-03],\n",
       "         [ 1.1847e-03,  1.3004e-03,  1.3311e-03,  ...,  1.2154e-03,\n",
       "           1.1456e-03,  9.0382e-04]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.6565e-04,  6.5153e-04,  4.2942e-04,  ...,  6.3372e-04,\n",
       "           6.9870e-04,  1.1188e-03],\n",
       "         [ 1.4382e-04,  6.5080e-04,  4.1145e-04,  ...,  4.5506e-04,\n",
       "           5.8571e-04,  8.8833e-04],\n",
       "         [ 2.0334e-04,  6.9536e-04,  4.5446e-04,  ...,  4.9010e-04,\n",
       "           4.6548e-04,  7.9592e-04],\n",
       "         ...,\n",
       "         [ 1.6189e-02,  1.2626e-02,  1.5192e-02,  ..., -1.0855e-02,\n",
       "          -5.6572e-03,  1.9723e-02],\n",
       "         [ 1.9139e-04,  6.4516e-04,  4.5656e-04,  ...,  5.1806e-04,\n",
       "           5.5144e-04,  8.9999e-04],\n",
       "         [ 4.0457e-05,  6.1667e-04,  4.2710e-04,  ...,  4.1371e-04,\n",
       "           6.2544e-04,  8.9523e-04]],\n",
       "\n",
       "        [[ 1.1082e-03,  1.2555e-03,  9.7156e-04,  ..., -2.2977e-04,\n",
       "          -3.6342e-04,  3.1451e-04],\n",
       "         [ 1.3571e-03,  1.5122e-03,  1.1176e-03,  ..., -1.3629e-04,\n",
       "          -3.1930e-04,  2.7349e-04],\n",
       "         [ 1.2619e-03,  1.4300e-03,  1.1231e-03,  ..., -1.6520e-04,\n",
       "          -3.1733e-04,  3.0157e-04],\n",
       "         ...,\n",
       "         [ 1.6376e-02,  1.8705e-02,  2.1022e-02,  ...,  1.0865e-02,\n",
       "           2.0447e-02,  3.8983e-03],\n",
       "         [ 1.2845e-03,  1.4085e-03,  1.1282e-03,  ..., -1.7915e-04,\n",
       "          -3.2780e-04,  3.0109e-04],\n",
       "         [ 1.1656e-03,  1.3738e-03,  9.8166e-04,  ..., -2.4259e-04,\n",
       "          -3.4657e-04,  1.8724e-04]],\n",
       "\n",
       "        [[ 1.4152e-03,  1.0904e-03,  1.9623e-03,  ..., -3.0537e-05,\n",
       "           4.1026e-04,  1.5376e-03],\n",
       "         [ 1.4786e-03,  1.2103e-03,  2.0670e-03,  ...,  1.7080e-04,\n",
       "           6.1113e-04,  1.7920e-03],\n",
       "         [ 1.5438e-03,  1.3268e-03,  2.1761e-03,  ...,  2.6257e-04,\n",
       "           5.6378e-04,  1.7597e-03],\n",
       "         ...,\n",
       "         [ 2.9834e-03,  2.0411e-02,  4.8005e-03,  ...,  8.0982e-03,\n",
       "           1.1781e-02,  1.2984e-02],\n",
       "         [ 1.6635e-03,  1.4177e-03,  2.2617e-03,  ...,  2.9717e-04,\n",
       "           6.1823e-04,  1.8004e-03],\n",
       "         [ 1.4079e-03,  1.1492e-03,  1.9974e-03,  ...,  1.5755e-04,\n",
       "           5.1301e-04,  1.8652e-03]]], device='cuda:0',\n",
       "       grad_fn=<GeluBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.model.feature_extractor(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1857,  0.0769,  0.3977,  ..., -0.8687,  0.2623,  0.0000],\n",
       "         [ 0.0000,  0.2378,  0.5511,  ..., -1.8676,  0.6503,  0.0643],\n",
       "         [ 0.0884,  0.0252,  0.4305,  ..., -1.1239,  0.4569,  0.0000],\n",
       "         ...,\n",
       "         [-0.6440, -0.0602,  0.4956,  ...,  1.6554, -0.2846, -0.0311],\n",
       "         [ 0.2597,  0.1765,  0.0596,  ..., -0.3161, -0.5654,  0.2011],\n",
       "         [-0.0552, -0.1849, -0.3153,  ...,  0.3303, -0.0757,  0.6304]],\n",
       "\n",
       "        [[-0.1254, -0.0303,  0.0689,  ..., -0.4109,  0.1515,  0.3123],\n",
       "         [-0.4545, -0.1595,  0.2852,  ..., -0.8969,  0.7662, -0.0000],\n",
       "         [-1.3589, -0.2886,  0.3215,  ..., -0.1405, -0.0090, -0.2662],\n",
       "         ...,\n",
       "         [ 0.7510, -0.0685, -0.2636,  ..., -0.2571,  0.0000, -0.6380],\n",
       "         [ 1.1083,  0.0932,  0.0091,  ..., -0.1345,  0.7107, -1.4082],\n",
       "         [ 1.6174,  0.2708, -0.0517,  ..., -0.9167,  1.6382, -0.0056]],\n",
       "\n",
       "        [[ 0.3804, -0.0479,  0.0997,  ..., -1.2887, -0.2636,  0.3358],\n",
       "         [ 0.2789, -0.1658, -0.0662,  ..., -0.0951, -0.1413,  0.1492],\n",
       "         [ 0.4938,  0.0942,  0.0814,  ..., -1.2644,  0.1445,  0.4656],\n",
       "         ...,\n",
       "         [-0.1730, -0.1054,  0.2221,  ..., -0.7111, -0.4254, -0.4228],\n",
       "         [-0.0000, -0.0945,  0.4775,  ..., -1.5903, -0.3311, -0.0409],\n",
       "         [-0.0630, -0.0487,  0.5148,  ..., -0.2485, -0.4602, -0.5510]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.2541, -0.0058, -0.2254,  ...,  0.9102, -0.2902,  0.0000],\n",
       "         [ 0.2835, -0.0814, -0.3676,  ...,  0.8592, -0.4274, -0.4047],\n",
       "         [ 0.3587,  0.0573, -0.0335,  ...,  0.5053,  0.1145,  0.5589],\n",
       "         ...,\n",
       "         [ 0.8658,  0.2592,  0.2320,  ...,  0.0000,  1.1673,  0.6674],\n",
       "         [ 0.2397,  0.0019,  0.2027,  ..., -0.0000,  0.2421, -0.2106],\n",
       "         [ 0.8258,  0.0287,  0.4229,  ..., -0.1680, -0.0380, -0.3566]],\n",
       "\n",
       "        [[-0.5349, -0.0314,  0.1207,  ..., -0.1414,  0.3927,  0.6866],\n",
       "         [-1.1379, -0.2190,  0.1402,  ...,  0.0713,  0.0000,  0.5916],\n",
       "         [-0.8957, -0.2710, -0.0952,  ..., -0.0418,  0.5810,  0.4689],\n",
       "         ...,\n",
       "         [-0.3733, -0.0799,  0.4099,  ..., -0.0451, -0.2839, -0.1922],\n",
       "         [-0.9237, -0.5574,  0.4137,  ...,  0.2190,  0.1169, -1.4669],\n",
       "         [-0.9466, -0.4949,  0.5972,  ...,  0.6424, -0.0000, -1.6448]],\n",
       "\n",
       "        [[-0.7139, -0.0519,  0.6731,  ...,  0.7024, -0.1746, -0.7707],\n",
       "         [-0.9991, -0.3334,  0.3525,  ...,  0.2459, -0.0000, -0.2135],\n",
       "         [-0.2756, -0.0819,  0.5313,  ..., -0.2612,  0.1591,  0.3892],\n",
       "         ...,\n",
       "         [ 0.0877,  0.0000, -0.3663,  ..., -0.7042,  0.5504, -0.3512],\n",
       "         [-0.0857,  0.0332, -0.7527,  ..., -0.3164,  1.4837, -0.4237],\n",
       "         [ 0.4632, -0.0000, -0.0000,  ..., -0.5358,  0.0000, -0.3892]]],\n",
       "       device='cuda:0', grad_fn=<NativeDropoutBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.model.feature_projection(encoder.model.feature_extractor(waveform).transpose(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.2652e-02,  1.5366e-01,  2.5070e-01,  ..., -2.7075e-01,\n",
       "           5.5647e-03, -5.6789e-01],\n",
       "         [ 2.3165e-01,  4.2435e-02,  1.5181e-01,  ..., -8.0031e-02,\n",
       "           2.1582e-02, -8.7625e-01],\n",
       "         [ 4.6178e-02,  3.1645e-01,  8.7990e-02,  ..., -3.1208e-01,\n",
       "           5.1273e-02, -1.1649e+00],\n",
       "         ...,\n",
       "         [ 4.5507e-03,  1.5237e-01, -1.6684e-01,  ..., -2.7230e-01,\n",
       "          -7.5107e-02, -1.0434e+00],\n",
       "         [ 4.0861e-03,  3.1525e-01,  9.1576e-02,  ..., -2.1161e-01,\n",
       "          -8.1003e-02,  6.7370e-01],\n",
       "         [ 3.0743e-01,  2.6195e-01,  6.8893e-03,  ...,  1.9722e-04,\n",
       "          -7.1389e-02,  6.9221e-01]],\n",
       "\n",
       "        [[ 9.6288e-03,  1.2530e-01,  2.9277e-01,  ...,  7.2687e-02,\n",
       "          -7.4341e-02, -4.0891e-02],\n",
       "         [ 4.4819e-02, -3.3666e-02,  3.1662e-01,  ..., -2.2837e-02,\n",
       "           7.7811e-02, -5.3007e-01],\n",
       "         [-1.0689e-01, -1.7001e-01,  5.6261e-01,  ...,  1.8448e-01,\n",
       "          -2.3359e-01, -2.9243e-01],\n",
       "         ...,\n",
       "         [-1.6722e-01,  1.9725e-01,  4.4934e-02,  ..., -6.0247e-01,\n",
       "          -1.7225e-01,  7.5562e-02],\n",
       "         [-3.1787e-02, -1.5603e-01,  6.8880e-02,  ..., -4.4855e-01,\n",
       "          -3.1375e-01, -2.1316e-01],\n",
       "         [ 1.1382e-01, -4.1508e-01,  1.2562e-01,  ..., -2.8480e-01,\n",
       "          -5.0444e-01, -9.1457e-01]],\n",
       "\n",
       "        [[-4.4296e-02, -7.4906e-02,  1.8752e-01,  ..., -1.0641e-01,\n",
       "          -8.1182e-02, -6.3441e-01],\n",
       "         [ 1.1100e-03, -6.6233e-02,  2.5390e-01,  ..., -2.6282e-02,\n",
       "           2.1744e-01, -7.3336e-01],\n",
       "         [ 1.7413e-01, -3.0912e-02,  1.7062e-01,  ..., -6.0741e-02,\n",
       "           2.6989e-01, -5.8223e-01],\n",
       "         ...,\n",
       "         [ 3.9655e-04,  9.3702e-02,  4.8083e-01,  ..., -4.1993e-02,\n",
       "          -4.8623e-01, -8.4570e-01],\n",
       "         [ 4.8505e-02,  4.3247e-02,  1.6307e-01,  ..., -3.4759e-01,\n",
       "          -2.1815e-01, -3.5990e-01],\n",
       "         [ 1.9283e-01,  9.0398e-02,  7.4332e-02,  ..., -4.7335e-01,\n",
       "          -3.2759e-01, -9.2081e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.2352e-01, -3.9863e-03,  3.5768e-01,  ..., -3.0016e-02,\n",
       "           1.0106e-01, -1.0075e-01],\n",
       "         [-9.0010e-02,  8.1450e-02,  4.5624e-01,  ..., -1.7747e-01,\n",
       "           9.3786e-02, -1.2245e-01],\n",
       "         [ 3.4401e-02,  8.5291e-02,  3.6562e-01,  ..., -2.1114e-01,\n",
       "           2.4390e-01, -6.4977e-01],\n",
       "         ...,\n",
       "         [-1.8111e-02,  6.5127e-02,  4.0059e-01,  ...,  1.0238e-02,\n",
       "           1.1993e-01, -5.0891e-01],\n",
       "         [-7.8886e-02, -1.0280e-01,  1.6424e-01,  ..., -1.7907e-02,\n",
       "          -1.2497e-01, -5.1407e-01],\n",
       "         [ 1.2038e-02,  1.9860e-01,  3.9326e-01,  ..., -3.8887e-02,\n",
       "           6.9288e-03, -2.6765e-01]],\n",
       "\n",
       "        [[-1.8246e-02,  2.7475e-01,  1.8281e-01,  ..., -7.5454e-02,\n",
       "          -6.7339e-02, -3.7227e-01],\n",
       "         [ 1.4467e-01,  2.7912e-01,  6.2706e-02,  ..., -2.1366e-01,\n",
       "          -7.3804e-02, -3.0639e-01],\n",
       "         [ 2.2783e-01,  3.9993e-01,  1.0387e-01,  ..., -2.4173e-01,\n",
       "          -2.0719e-01, -7.2665e-01],\n",
       "         ...,\n",
       "         [ 1.9165e-01, -5.3735e-02, -1.6419e-01,  ..., -2.9159e-01,\n",
       "          -2.1156e-01,  5.7159e-01],\n",
       "         [ 1.1369e-02,  1.7304e-01, -2.7187e-01,  ..., -3.8190e-01,\n",
       "          -1.6181e-02,  1.8855e-02],\n",
       "         [ 1.2713e-01,  1.7993e-01, -1.1981e-02,  ..., -4.5106e-01,\n",
       "          -1.0113e-01, -4.8440e-01]],\n",
       "\n",
       "        [[-9.6001e-02, -3.6195e-03,  2.5504e-01,  ..., -4.4023e-01,\n",
       "          -2.8706e-03, -5.9701e-01],\n",
       "         [-2.6304e-01,  1.1004e-01,  2.8421e-01,  ..., -5.1515e-01,\n",
       "           1.1877e-01, -4.1481e-01],\n",
       "         [-4.3682e-01,  8.5356e-02,  3.8892e-01,  ..., -1.9768e-01,\n",
       "          -4.9725e-02, -3.6140e-01],\n",
       "         ...,\n",
       "         [ 3.3219e-01,  9.7719e-03,  5.8597e-02,  ...,  6.6499e-02,\n",
       "          -7.1693e-03,  3.1588e-01],\n",
       "         [-1.5699e-01,  4.2363e-01,  7.6542e-02,  ...,  1.7209e-01,\n",
       "           1.6667e-01, -3.4400e-01],\n",
       "         [-1.2350e-01,  3.0716e-01,  4.8936e-02,  ..., -6.8542e-02,\n",
       "           1.6379e-02, -5.4570e-01]]], device='cuda:0',\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.model.encoder(encoder.model.feature_projection(encoder.model.feature_extractor(waveform).transpose(1,2)))['last_hidden_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices: tensor([20, 20, 20, 20, 20,  5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 20,  4,  5,  4, 20, 20,  5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,  5, 20, 20, 20,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20,  5,  5, 20], device='cuda:0')\n",
      "Epoch: 0, Iteration: 0/765, Loss: 17.163265228271484, commit_loss: 9.549200057983398, l2_loss: 7.614066123962402\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      9\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# data\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     waveform, speaker \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     13\u001b[0m     waveform \u001b[38;5;241m=\u001b[39m waveform\u001b[38;5;241m.\u001b[39mto(device) \n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1295\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def merge_tensors(t1, t2):\n",
    "    t2 = t2.unsqueeze(-1)  # Reshape to (batch, features, 1)\n",
    "    return torch.cat([t1, t2.expand(-1, -1, t1.shape[-1])], dim=1)\n",
    "\n",
    "# start training\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    running_loss = 0.0\n",
    "    for iteration, data in enumerate(dataloader):\n",
    "        # data\n",
    "        waveform, speaker = data\n",
    "        waveform = waveform.to(device) \n",
    "        speaker = torch.tensor(speaker).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            encoder_output = encoder(waveform)\n",
    "        downsampling_output = downsampling(encoder_output) # torch.Size([32, 768, 172])\n",
    "        # Get the closest vocab embeddings\n",
    "        commitment_loss, vocab_output, indices = get_closest_vocab(downsampling_output, vocab_embeddings)\n",
    "        \n",
    "        # add speaker embeddings\n",
    "        speaker = spk_embed(speaker)\n",
    "        vocab_output = merge_tensors(vocab_output, speaker)\n",
    "\n",
    "        \n",
    "        # Upsampling\n",
    "        upsampling_output = upsampling(vocab_output)\n",
    "        # Decoder\n",
    "        decoder_output = decoder(upsampling_output).contiguous() # torch.Size([32, 1024, 172])\n",
    "        \n",
    "        # Codec\n",
    "        with torch.no_grad():\n",
    "            codec_output = codec.encode(waveform).detach().contiguous()\n",
    "        \n",
    "        # Ensure same sequence length for ground truth and output\n",
    "        min_seq_len = min(codec_output.shape[-1], decoder_output.shape[-1])    \n",
    "        codec_output = codec_output[:, :, :min_seq_len]\n",
    "        decoder_output = decoder_output[:, :, :min_seq_len]    \n",
    "\n",
    "        # Compute the loss\n",
    "        l2_loss = F.mse_loss(decoder_output, codec_output)\n",
    "        commitment_loss *= 10\n",
    "        loss =  l2_loss + commitment_loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # empty cache\n",
    "        torch.cuda.empty_cache()  \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # print for every 10 iterations\n",
    "        if iteration % 10 == 0:\n",
    "            print(f\"Indices: {indices[0]}\")\n",
    "            print(f\"Epoch: {epoch}, Iteration: {iteration}/{len(dataloader)}, Loss: {running_loss/(iteration+1)}, commit_loss: {commitment_loss.item()}, l2_loss: {l2_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = indices\n",
    "\"\".join([idx_to_char[i] for i in merge_similar_indices(ind)[0]]) #.replace(\"<sil>\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode audio signal\n",
    "y = codec.model.decode(decoder_output[1:2,:,:]).cpu().detach().numpy()\n",
    "\n",
    "# play the numpy array as audio using ipython.display.Audio\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(y[0,0,:], rate=16000)  # load a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(waveform[1,:].cpu().detach().numpy(), rate=16000)  # load a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "last",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
