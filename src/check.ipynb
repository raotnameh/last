{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "indices = torch.randint(0, 2, (2, 5))\n",
    "tensor = torch.rand((2, 5, 2))\n",
    "pad_e = torch.zeros((1, 1, 2))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length 3\n",
      "chosen_indices [tensor([2, 3, 4]), tensor([0, 3])]\n",
      "torch.Size([1, 3, 2])\n",
      "dummy tensor([[0.0274, 0.0332],\n",
      "        [0.0860, 0.8944],\n",
      "        [0.3660, 0.7036]])\n",
      "pad_len 0\n",
      "torch.Size([1, 2, 2])\n",
      "dummy tensor([[0.2411, 0.3674],\n",
      "        [0.3298, 0.8448]])\n",
      "pad_len 1\n",
      "pad torch.Size([1, 1, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Tensors must have same number of dimensions: got 2 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 48\u001b[0m\n\u001b[1;32m     44\u001b[0m     z_q_disc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(dummy, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m z_q_disc\n\u001b[0;32m---> 48\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mrandomly_keep_one_with_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[114], line 41\u001b[0m, in \u001b[0;36mrandomly_keep_one_with_indices\u001b[0;34m(indices, pad_e, z_q)\u001b[0m\n\u001b[1;32m     39\u001b[0m         pad \u001b[38;5;241m=\u001b[39m pad_e\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, pad_len,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpad\u001b[39m\u001b[38;5;124m\"\u001b[39m, pad\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 41\u001b[0m         dummy[r] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdummy\u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# concatenate the rows\u001b[39;00m\n\u001b[1;32m     44\u001b[0m z_q_disc \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(dummy, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tensors must have same number of dimensions: got 2 and 3"
     ]
    }
   ],
   "source": [
    "\n",
    "def randomly_keep_one_with_indices(indices, pad_e, z_q):\n",
    "    chosen_indices = []\n",
    "\n",
    "    for row_idx, row in enumerate(indices):\n",
    "        row_indices = []\n",
    "        i = 0\n",
    "\n",
    "        while i < len(row):\n",
    "            value = row[i].item()\n",
    "            \n",
    "            # Detect consecutive duplicates\n",
    "            j = i + 1\n",
    "            while j < len(row) and row[j].item() == value:\n",
    "                j += 1\n",
    "            \n",
    "            # Randomly select one index from the range\n",
    "            random_index = random.randint(i, j - 1)\n",
    "            row_indices.append(random_index)  # Track chosen index\n",
    "            \n",
    "            # Move to next unique value\n",
    "            i = j\n",
    "\n",
    "        chosen_indices.append(torch.tensor(row_indices, device=indices.device))\n",
    "    \n",
    "    # extract the embedding from z_q and pad to the length of the longest row with pad_e\n",
    "    max_length = max(len(ind) for ind in chosen_indices)\n",
    "    print(\"max_length\", max_length)\n",
    "    print(\"chosen_indices\", chosen_indices)\n",
    "    dummy = []\n",
    "    for r, ind in enumerate(chosen_indices):\n",
    "        dummy.append(z_q[r, ind].unsqueeze(0))\n",
    "        print(z_q[r, ind].unsqueeze(0).shape)\n",
    "        \n",
    "        print(\"dummy\", dummy[r])    \n",
    "        # pad the row with pad_e\n",
    "        pad_len = max_length - len(ind)\n",
    "        print(\"pad_len\", pad_len)\n",
    "        if pad_len > 0:\n",
    "            pad = pad_e.repeat(1, pad_len,1)\n",
    "            print(\"pad\", pad.shape)\n",
    "            dummy[r] = torch.cat([dummy[r], pad], dim=1)\n",
    "    \n",
    "    # concatenate the rows\n",
    "    z_q_disc = torch.cat(dummy, dim=0)\n",
    "\n",
    "    return z_q_disc\n",
    "\n",
    "out = randomly_keep_one_with_indices(indices, pad_e, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2411, 0.3674],\n",
       "        [0.8927, 0.3168],\n",
       "        [0.4515, 0.9828],\n",
       "        [0.3298, 0.8448],\n",
       "        [0.2756, 0.1185]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0274, 0.0332],\n",
       "         [0.0860, 0.8944],\n",
       "         [0.3660, 0.7036]],\n",
       "\n",
       "        [[0.8927, 0.3168],\n",
       "         [0.2756, 0.1185],\n",
       "         [0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "last",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
