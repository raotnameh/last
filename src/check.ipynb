{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.8454,  0.3304],\n",
       "          [-1.3009,  0.7267],\n",
       "          [ 2.2446, -0.9767],\n",
       "          [ 2.5101, -1.4793],\n",
       "          [ 0.4955, -0.4704],\n",
       "          [ 1.2795,  0.7289]],\n",
       " \n",
       "         [[-0.2518, -0.3794],\n",
       "          [-0.9299, -0.1263],\n",
       "          [-1.2400,  1.1243],\n",
       "          [-0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000],\n",
       "          [-0.0000, -0.0000]]]),\n",
       " tensor([[1., 1., 1., 1., 1., 1.],\n",
       "         [1., 1., 1., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "def remove_consecutive_repeated_indices_optimized(min_encoding_indices, mask, z_q):\n",
    "    B, T = min_encoding_indices.shape\n",
    "    selected_indices_list = []\n",
    "    max_len = 0\n",
    "\n",
    "    for b in range(B):\n",
    "        indices = min_encoding_indices[b]\n",
    "        selected_indices = []\n",
    "        start = 0\n",
    "        for i in range(1, T):\n",
    "            if mask[b, i] == 0:\n",
    "                break\n",
    "            if indices[i] != indices[i - 1]:\n",
    "                selected_indices.append(random.randint(start, i - 1))\n",
    "                start = i\n",
    "        selected_indices.append(random.randint(start, T - 1))\n",
    "\n",
    "        selected_indices_list.append(torch.tensor(selected_indices))\n",
    "        max_len = max(max_len, len(selected_indices))\n",
    "\n",
    "    # Pad and create mask in a vectorized way\n",
    "    padded_indices = torch.zeros((B, max_len), dtype=min_encoding_indices.dtype)\n",
    "    masks = torch.zeros((B, max_len), dtype=torch.float)\n",
    "\n",
    "    for b, indices in enumerate(selected_indices_list):\n",
    "        length = len(indices)\n",
    "        padded_indices[b, :length] = indices\n",
    "        masks[b, :length] = 1\n",
    "\n",
    "    # Gather and apply mask\n",
    "    out = padded_indices.unsqueeze(-1).expand(-1, -1, z_q.shape[-1])\n",
    "    n_z_q = z_q.gather(dim=1, index=out)\n",
    "    n_z_q *= masks.unsqueeze(-1)\n",
    "\n",
    "    return n_z_q, masks\n",
    "\n",
    "\n",
    "mask = torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0]])\n",
    "min_encoding_indices = torch.tensor([[1, 1, 2, 2, 3, 4, 3, 5], [2,3, 3, 3, 2, 2, 2, 2]])\n",
    "z_q = torch.randn(2, 8, 2) # (B,T,C)\n",
    "remove_consecutive_repeated_indices_optimized(min_encoding_indices, mask, z_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1, 2, 2, 3, 4, 3, 5],\n",
       "         [2, 3, 3, 3, 2, 2, 2, 2]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0]]))"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_encoding_indices, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1182, -1.3978],\n",
       "         [-0.7669, -2.1116],\n",
       "         [ 1.4357, -1.0185],\n",
       "         [ 0.1194,  1.1072],\n",
       "         [-0.4323, -0.7386],\n",
       "         [-1.0836,  0.8543],\n",
       "         [-0.9251,  0.6196],\n",
       "         [ 1.0231,  1.6800]],\n",
       "\n",
       "        [[ 1.1913,  0.7126],\n",
       "         [-0.5653, -0.7836],\n",
       "         [-0.0749,  0.9504],\n",
       "         [ 0.7116,  0.1887],\n",
       "         [-1.0938,  0.9753],\n",
       "         [ 2.0332,  0.2463],\n",
       "         [-0.2469, -0.8310],\n",
       "         [ 0.8509, -0.0595]]])"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "last",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
