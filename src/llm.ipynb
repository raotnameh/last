{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c68306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68e0f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "# Initialize the model and tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "model.eval()\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4836b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"QQUQ ZQIQ'Q QZ OZFQOXOTOX'OQX'Q Q QQ QHQUQUX QJKJQXA'ZQQOXQHOQHZQ'XC'QXQHY QQ Q UQ XQ QYQ QX FQOQCOQOZQUL YQZQZGOQH OXVFQ\", \"IT MAY BE NOTHING MORE THAN HANGING THE SCREEN DOOR CHOPPING THE WOOD OR DUSTING THE FURNITURE BUT IT WILL FURNISH HIM WITH SOME KIND OF ACTIVITY BECAUSE HE ENJOYS ACTION FOR ITS OWN SAKE AND BECAUSE WORK IS ONLY APPLIED ACTION THIS TYPE MAKES THE BEST WORKER\"]\n",
    "# Get the rewards using a LLM as Judge.\n",
    "with torch.no_grad():\n",
    "    inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"] # 0 for padding\n",
    "            \n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    log_probs = F.log_softmax(outputs.logits, dim=-1)  # (B, T, V)\n",
    "    \n",
    "    target_ids = input_ids[:, 1:]\n",
    "    log_probs = log_probs[:, :-1, :]\n",
    "    token_log_probs = log_probs.gather(dim=2, index=target_ids.unsqueeze(-1)).squeeze(-1)\n",
    "    target_mask = attention_mask[:, 1:]\n",
    "    token_log_probs = token_log_probs * target_mask\n",
    "    \n",
    "rewards = token_log_probs.sum(dim=1) # per-sentence sum of log-probs shape: (B,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4571034f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-359.8435, -228.8658])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f346d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
