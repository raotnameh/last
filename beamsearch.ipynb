{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1, 2, 2, 2])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([\n",
    "    [1, 1, 2, 2, 3, 3, 2,3,2,3],\n",
    "])\n",
    "\n",
    "# Step 1: Create mask to keep first element and non-duplicates\n",
    "mask = torch.ones_like(x, dtype=torch.bool)\n",
    "mask[:, 1:] = x[:, 1:] != x[:, :-1]\n",
    "\n",
    "# Step 2: Remove a specific index (e.g., 3)\n",
    "remove_val = 3\n",
    "mask &= x != remove_val  # Elementwise AND: keep only those not equal to 3\n",
    "\n",
    "# Apply mask (as an example)\n",
    "filtered = [x[i][mask[i]] for i in range(x.size(0))]\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928dd7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1, 2, 3, 2, 3, 2])]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf71c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "927a7aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 2, 0, 2, 3, 0])\n",
      "tensor([1, 2, 2, 3])\n",
      "Decoded string: abbc\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "\n",
    "# Define vocab (index 0 is blank)\n",
    "vocab = ['_', 'a', 'b', 'c']\n",
    "blank_id = 0\n",
    "\n",
    "# Example model output (index sequence)\n",
    "output = torch.tensor([1, 1, 0, 2, 2, 0, 2, 2, 3, 3, 0])\n",
    "\n",
    "# Step 1: Collapse consecutive repeats\n",
    "# Create a mask to keep only non-duplicate consecutive elements\n",
    "mask = torch.ones_like(output, dtype=torch.bool)\n",
    "mask[1:] = output[1:] != output[:-1]\n",
    "collapsed = output[mask]\n",
    "print(collapsed)\n",
    "# Step 2: Remove blanks (i.e., tokens with index 0)\n",
    "final = collapsed[collapsed != blank_id]\n",
    "print(final)\n",
    "# Step 3: Convert indices to characters using vocab\n",
    "decoded_string = ''.join(vocab[i] for i in final.tolist())\n",
    "\n",
    "print(\"Decoded string:\", decoded_string)  # → 'bbc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1a97b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False,  True, False, False,  True, False,  True, False,\n",
       "         False]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38c4ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "c = np.array(['a','b','c','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed94b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ccf8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b', 'c', 'd'], dtype='<U1')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[filtered[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ca1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbda970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ClapProcessor, ClapModel\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "# Load model and processor\n",
    "processor = ClapProcessor.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "model = ClapModel.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "\n",
    "# Load and preprocess audio\n",
    "def load_audio(path):\n",
    "    waveform, sr = torchaudio.load(path)\n",
    "    if sr != 48000:\n",
    "        resampler = torchaudio.transforms.Resample(sr, 48000)\n",
    "        waveform = resampler(waveform)\n",
    "    return waveform\n",
    "\n",
    "audio_path = \"/raid/home/rajivratn/hemant_rajivratn/librispeech/data/train/audio/train-clean-100_126791_298_53.wav\"\n",
    "audio = load_audio(audio_path)\n",
    "\n",
    "# CLAP expects mono\n",
    "if audio.shape[0] > 1:\n",
    "    audio = torch.mean(audio, dim=0, keepdim=True)\n",
    "\n",
    "# Pad or truncate to 10s (CLAP expects 480000 samples)\n",
    "audio = torch.nn.functional.pad(audio, (0, max(0, 480000 - audio.shape[1])))[:, :480000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df6c2ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'speak i beg without dread of my displeasure said frances returning the good humored smile of the trooper with the archness natural to her own sweet face the odors of your kitchen then cried lawton bluntly forbid my quitting the domains until i qualify myself to speak with more certainty concerning the fatness of the land'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"SPEAK I BEG WITHOUT DREAD OF MY DISPLEASURE SAID FRANCES RETURNING THE GOOD HUMORED SMILE OF THE TROOPER WITH THE ARCHNESS NATURAL TO HER OWN SWEET FACE THE ODORS OF YOUR KITCHEN THEN CRIED LAWTON BLUNTLY FORBID MY QUITTING THE DOMAINS UNTIL I QUALIFY MYSELF TO SPEAK WITH MORE CERTAINTY CONCERNING THE FATNESS OF THE LAND\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6c39091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to `ClapFeatureExtractor()`. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Process audio and text\n",
    "texts = [\"hello how are you\", \"this is a dog barking\", \"there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with\", \"speak i beg without dread of my displeasure said frances returning the good humored smile of the trooper with the archness natural to her own sweet face the odors of your kitchen then cried lawton bluntly forbid my quitting the domains until i qualify myself to speak with more certainty concerning the fatness of the land\"]\n",
    "inputs = processor(audios=audio.squeeze().numpy(), text=texts, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    audio_embeds = outputs.audio_embeds\n",
    "    text_embeds = outputs.text_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speak i beg without dread of my displeasure said frances returning the good humored smile of the trooper with the archness natural to her own sweet face the odors of your kitchen then cried lawton bluntly forbid my quitting the domains until i qualify myself to speak with more certainty concerning the fatness of the land -> Similarity: 0.5616\n",
      "there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with -> Similarity: 0.5157\n",
      "hello how are you              -> Similarity: 0.0358\n",
      "this is a dog barking          -> Similarity: -0.1362\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Normalize embeddings\n",
    "audio_embeds = torch.nn.functional.normalize(audio_embeds, dim=-1)\n",
    "text_embeds = torch.nn.functional.normalize(text_embeds, dim=-1)\n",
    "\n",
    "# Cosine similarity\n",
    "similarities = torch.matmul(audio_embeds, text_embeds.T).squeeze(0)\n",
    "\n",
    "# Print ranked results\n",
    "for text, score in sorted(zip(texts, similarities), key=lambda x: -x[1]):\n",
    "    print(f\"{text:<30} -> Similarity: {score.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd7248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a570bd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591dc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ea89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "model = kenlm.Model(\"/raid/home/rajivratn/hemant_rajivratn/grpo/3-gram.pruned.1e-7.arpa.gz\")\n",
    "\n",
    "sentence = \"this is a test\".upper()\n",
    "print(sentence)\n",
    "\n",
    "# Each tuple means “this word had log10-prob logp given the previous context; ng_len is the n-gram order (e.g. 3 means a trigram was used), and oov marks out-of-vocabulary\n",
    "for (logp, ng_len, oov) in model.full_scores(sentence, bos=False, eos=False):\n",
    "    print(logp, ng_len, oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram(sentences):\n",
    "    for s in sentences:\n",
    "        log10p = [model.score(w, bos=False, eos=False) for w in sentence.split() if model.vocab_index(w) != 0]\n",
    "\n",
    "unigram([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf230ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_unigram_char_probs(sentences):\n",
    "    # Flatten to a list of characters\n",
    "    chars = [char for sentence in sentences for char in sentence.strip()]\n",
    "    \n",
    "    # Count frequency of each character\n",
    "    char_counts = Counter(chars)\n",
    "    total_chars = sum(char_counts.values())\n",
    "\n",
    "    # Convert to probabilities\n",
    "    char_probs = {char: count / total_chars for char, count in char_counts.items()}\n",
    "    \n",
    "    return char_probs, chars\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    'THANK YOU AGAIN MISTER DEVANT HE SAID...',\n",
    "    'FOR WEEKS IT NEVER CAME TO MY TURN...',\n",
    "    'ONE MAN WON PAST ME INDEED DARTING...'\n",
    "]\n",
    "\n",
    "char_probs, chars = get_unigram_char_probs(sentences)\n",
    "\n",
    "# Print sorted for readability\n",
    "for char, prob in sorted(char_probs.items()):\n",
    "    print(f\"'{char}': {prob:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac18c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/raid/home/rajivratn/hemant_rajivratn/last/data/txt/train_norm.txt\", \"r\") as f:\n",
    "    out = [i for i in f.readlines() if len(i.strip()) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa0108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40407482/40407482 [01:48<00:00, 373406.29it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def preprocess_char_lm(sentences):\n",
    "    \"\"\"Prep a list of sentences for char-level n-gram LM training.\"\"\"\n",
    "    preprocessed = []\n",
    "    for s in tqdm(sentences):\n",
    "        s = s.strip().replace(\" \", \"|\")\n",
    "        chars = list(s)\n",
    "        line = \"<s> \" + \" \".join(chars) + \" </s>\"\n",
    "        preprocessed.append(line)\n",
    "    return preprocessed\n",
    "\n",
    "char_lm_lines = preprocess_char_lm(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f05e7951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to char_lm_input.txt\n"
     ]
    }
   ],
   "source": [
    "output_path = \"char_lm_input.txt\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in char_lm_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"Saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "@torch.jit.script\n",
    "def beam_search(log_probs: torch.Tensor, beam_size: int):\n",
    "    \"\"\"\n",
    "    Performs beam search on a tensor of log probabilities.\n",
    "\n",
    "    Args:\n",
    "        log_probs (torch.Tensor): Tensor of shape (b, t, v) containing log probabilities.\n",
    "        beam_size (int): Number of beams to keep at each time step.\n",
    "\n",
    "    Returns:\n",
    "        sequences (torch.Tensor): Tensor of shape (b, beam_size, t) containing the top sequences.\n",
    "        scores (torch.Tensor): Tensor of shape (b, beam_size) containing the scores of the top sequences.\n",
    "    \"\"\"\n",
    "    \n",
    "    b, t, v = log_probs.size()\n",
    "    \n",
    "    initial_beam_size = min(beam_size, v) # At the very first step (time step 0), we can't have more beams than the vocabulary size. This line ensures that the initial number of beams considered doesn't exceed the number of possible first tokens.\n",
    "\n",
    "    topk_scores, topk_indices = torch.topk(log_probs[:, 0, :], initial_beam_size, dim=-1) # Returns the k largest elements of the given input tensor along a given dimension\n",
    "    sequences = topk_indices.unsqueeze(-1)  # (b, initial_beam_size, 1)\n",
    "    scores = topk_scores  # (b, initial_beam_size)\n",
    "\n",
    "    for step in range(1, t):\n",
    "        # Expand the current sequences with all possible next tokens\n",
    "        current_log_probs = log_probs[:, step, :].unsqueeze(1)  # (b, 1, v)\n",
    "        expanded_scores = scores.unsqueeze(-1) + current_log_probs  # (b, beam_size, v)\n",
    "        flat_scores = expanded_scores.view(b, -1)  # (b, beam_size * v)\n",
    "\n",
    "        # Select the top-k scores and their corresponding indices\n",
    "        topk_flat_scores, topk_indices = flat_scores.topk(beam_size, dim=-1)  # (b, beam_size)\n",
    "        beam_indices = topk_indices // v  # Indices of sequences to expand\n",
    "        token_indices = topk_indices % v  # New tokens to append\n",
    "\n",
    "        # Gather the sequences to expand and append the new tokens\n",
    "        sequences = torch.gather(sequences, 1, beam_indices.unsqueeze(-1).expand(-1, -1, sequences.size(-1)))\n",
    "        sequences = torch.cat([sequences, token_indices.unsqueeze(-1)], dim=-1)  # (b, beam_size, step+1)\n",
    "\n",
    "        # Update the scores\n",
    "        scores = topk_flat_scores\n",
    "\n",
    "    return sequences, scores.unsqueeze(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "sequence_length = 5\n",
    "vocab_size = 3\n",
    "beam_size = 2\n",
    "\n",
    "# Simulate log probabilities\n",
    "log_probs = torch.randn(batch_size, sequence_length, vocab_size).log_softmax(dim=-1)\n",
    "device = torch.device('cpu')\n",
    "log_probs = log_probs.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs[1,3:,:] = -float(\"1000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c28fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a06a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform beam search\n",
    "sequences, scores = beam_search(log_probs, beam_size)\n",
    "\n",
    "print(\"Top sequences:\", sequences) # bsz, beamsize,seq_len\n",
    "print(\"Scores:\", scores) # bsz, beamsize,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences.shape, scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_probs = torch.gather(log_probs, 2, sequences.transpose(1,2)).transpose(1,2) # bsz, beamsize, T\n",
    "path_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fefdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = scores.mean(dim=1, keepdim=True)\n",
    "std = scores.std(dim=1, keepdim=True)\n",
    "\n",
    "scores = (scores - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeda04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_probs*scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences # bsz,beam,T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed129f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using PyTorch\n",
    "import torch\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "vocab = [' ', \"'\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '?']\n",
    "vocab = np.array(vocab)\n",
    "\n",
    "\n",
    "# Precompile regex to remove blanks and collapse repeats\n",
    "blank_char = re.escape('?')  # adjust if blank differs\n",
    "remove_blanks = re.compile(blank_char)\n",
    "collapse_repeats = re.compile(r'(.)\\1+')\n",
    "\n",
    "# Convert token sequences to strings using regex merge\n",
    "def decode(arr, vocab):\n",
    "    raw = [collapse_repeats.sub(r'\\1', remove_blanks.sub('', ''.join(vocab[row]))) for row in arr]\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846d4700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert token sequences to strings using regex merge\n",
    "def decode(arr, vocab):\n",
    "    raw = [collapse_repeats.sub(r'\\1', remove_blanks.sub('', ''.join(vocab[row]))) for row in arr]\n",
    "    return raw\n",
    "\n",
    "sentences = decode(sequences[0].cpu(), vocab)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dd92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences[0], vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = sequences[1,:,:]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2657461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vocab_arr = np.array(vocab)\n",
    "\n",
    "decoded = [''.join(vocab_arr[row]) for row in arr]\n",
    "print(decoded)  # ['abc', 'cba']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288be618",
   "metadata": {},
   "outputs": [],
   "source": [
    "[collapse_repeats.sub(r'\\1', remove_blanks.sub('', ''.join(vocab[row]))) for row in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90407d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[''.join(vocab[row]) for row in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc135d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode(arr, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ec8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'-'.join(vocab[np.array(arr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b57304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: vocab and array of indices\n",
    "vocab = ['a', 'b', 'c', 'd', 'e']\n",
    "vocab_arr = np.array(vocab)  # shape (V,)\n",
    "arr = np.array([\n",
    "    [0, 1, 2],\n",
    "    [2, 3, 4],\n",
    "])  # shape (2, 3)\n",
    "\n",
    "# Step 2: index vocab\n",
    "char_matrix = vocab_arr[arr]  # shape (2, 3), dtype='<U1'\n",
    "\n",
    "# Step 3: vectorized join — this is the key step!\n",
    "joined = np.char.join('-', char_matrix)  # shape (2,), dtype='<U5' etc.\n",
    "\n",
    "print(joined)  # Output: ['a-b-c' 'c-d-e']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8502bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = ['-'.join(vocab[row]) for row in arr]\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b675c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5436f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arr = torch.tensor([[0, 1, 2], [2, 1, 0]])\n",
    "decoded = [''.join(vocab_arr[row]) for row in arr.numpy()]\n",
    "print(decoded)  # ['abc', 'cba']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [decode_one(seq, vocab) for seq in sequences[0,:,:].cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8511fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b99a96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee00fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) move to CPU & to plain Python list of lists\n",
    "sentences = []\n",
    "for b in range(sequences.shape[0]):\n",
    "    print(b)\n",
    "    rows = sequences[b].cpu().tolist() # beam,T\n",
    "    decoded_beams = [ctc_merge_string( ''.join(idx2char[i] for i in row) ) for row in rows]\n",
    "    sentences.append(decoded_beams)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _decode_one( seq):\n",
    "    chars = [vocab[i] for i in seq]\n",
    "    raw = ''.join(chars)\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c276fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a152fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_decode_one(sequences[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afcac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.  beamctc decoder\n",
    "2. \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22aa42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6669dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
