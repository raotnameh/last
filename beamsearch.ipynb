{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f5a042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@torch.jit.script\n",
    "def beam_search(log_probs: torch.Tensor, beam_size: int):\n",
    "    \"\"\"\n",
    "    Performs beam search on a tensor of log probabilities.\n",
    "\n",
    "    Args:\n",
    "        log_probs (torch.Tensor): Tensor of shape (b, t, v) containing log probabilities.\n",
    "        beam_size (int): Number of beams to keep at each time step.\n",
    "\n",
    "    Returns:\n",
    "        sequences (torch.Tensor): Tensor of shape (b, beam_size, t) containing the top sequences.\n",
    "        scores (torch.Tensor): Tensor of shape (b, beam_size) containing the scores of the top sequences.\n",
    "    \"\"\"\n",
    "    \n",
    "    b, t, v = log_probs.size()\n",
    "    \n",
    "    initial_beam_size = min(beam_size, v) # At the very first step (time step 0), we can't have more beams than the vocabulary size. This line ensures that the initial number of beams considered doesn't exceed the number of possible first tokens.\n",
    "\n",
    "    topk_scores, topk_indices = torch.topk(log_probs[:, 0, :], initial_beam_size, dim=-1) # Returns the k largest elements of the given input tensor along a given dimension\n",
    "    sequences = topk_indices.unsqueeze(-1)  # (b, initial_beam_size, 1)\n",
    "    scores = topk_scores  # (b, initial_beam_size)\n",
    "\n",
    "    for step in range(1, t):\n",
    "        # Expand the current sequences with all possible next tokens\n",
    "        current_log_probs = log_probs[:, step, :].unsqueeze(1)  # (b, 1, v)\n",
    "        expanded_scores = scores.unsqueeze(-1) + current_log_probs  # (b, beam_size, v)\n",
    "        flat_scores = expanded_scores.view(b, -1)  # (b, beam_size * v)\n",
    "\n",
    "        # Select the top-k scores and their corresponding indices\n",
    "        topk_flat_scores, topk_indices = flat_scores.topk(beam_size, dim=-1)  # (b, beam_size)\n",
    "        beam_indices = topk_indices // v  # Indices of sequences to expand\n",
    "        token_indices = topk_indices % v  # New tokens to append\n",
    "\n",
    "        # Gather the sequences to expand and append the new tokens\n",
    "        sequences = torch.gather(sequences, 1, beam_indices.unsqueeze(-1).expand(-1, -1, sequences.size(-1)))\n",
    "        sequences = torch.cat([sequences, token_indices.unsqueeze(-1)], dim=-1)  # (b, beam_size, step+1)\n",
    "\n",
    "        # Update the scores\n",
    "        scores = topk_flat_scores\n",
    "\n",
    "    return sequences, scores.unsqueeze(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a06a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top sequences: tensor([[[24, 12, 20, 25, 24,  1, 24, 13, 23,  4],\n",
      "         [24, 12, 20, 25, 24,  1, 24, 13, 16,  4]],\n",
      "\n",
      "        [[ 1,  3, 13,  1, 14,  7, 28, 28, 21,  4],\n",
      "         [ 1,  3,  6,  1, 14,  7, 28, 28, 21,  4]]], device='cuda:0')\n",
      "Scores: tensor([[[-17.9353],\n",
      "         [-17.9991]],\n",
      "\n",
      "        [[-18.7701],\n",
      "         [-18.9559]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "sequence_length = 10\n",
    "vocab_size = 30\n",
    "beam_size = 2\n",
    "\n",
    "# Simulate log probabilities\n",
    "log_probs = torch.randn(batch_size, sequence_length, vocab_size).log_softmax(dim=-1)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "log_probs = log_probs.to(device)\n",
    "\n",
    "# Perform beam search\n",
    "sequences, scores = beam_search(log_probs, beam_size)\n",
    "\n",
    "print(\"Top sequences:\", sequences)\n",
    "print(\"Scores:\", scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ecae46a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2, 10]), torch.Size([2, 2, 1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.shape, scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22f4cfbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7071],\n",
       "         [-0.7071]],\n",
       "\n",
       "        [[ 0.7071],\n",
       "         [-0.7071]]], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_scores = torch.mean(scores, dim=1, keepdim=True)\n",
    "std_scores = torch.std(scores, dim=1, keepdim=True)\n",
    "\n",
    "(scores - mean_scores ) / std_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22d713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7a152fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            beam_search        18.14%     695.342us        99.55%       3.817ms       3.817ms     761.000us        19.91%       3.823ms       3.823ms             1  \n",
      "                                     aten::floor_divide         5.20%     199.467us        15.51%     594.651us      33.036us     315.000us         8.24%     660.000us      36.667us            18  \n",
      "                                             aten::topk         6.33%     242.816us        13.55%     519.406us      51.941us     474.000us        12.40%     583.000us      58.300us            10  \n",
      "                                        aten::remainder         4.10%     157.227us         9.15%     350.742us      19.486us     266.000us         6.96%     422.000us      23.444us            18  \n",
      "                                           aten::gather         5.72%     219.355us         9.09%     348.351us      38.706us     314.000us         8.21%     386.000us      42.889us             9  \n",
      "                                            aten::slice         4.33%     165.892us         7.10%     272.096us      13.605us     256.000us         6.70%     345.000us      17.250us            20  \n",
      "                                       aten::as_strided         1.60%      61.279us         1.60%      61.279us       0.806us     316.000us         8.27%     316.000us       4.158us            76  \n",
      "                                        aten::unsqueeze         3.32%     127.284us         5.85%     224.197us      11.800us     215.000us         5.62%     292.000us      15.368us            19  \n",
      "                                              aten::cat         3.54%     135.677us         4.55%     174.301us      19.367us     213.000us         5.57%     213.000us      23.667us             9  \n",
      "                          fused_unsqueeze_unsqueeze_add         2.82%     107.994us         3.82%     146.287us      16.254us     186.000us         4.87%     186.000us      20.667us             9  \n",
      "                                           aten::select         2.42%      92.730us         3.76%     144.314us      14.431us     140.000us         3.66%     181.000us      18.100us            10  \n",
      "                                           aten::expand         2.03%      77.801us         3.22%     123.636us      13.737us     121.000us         3.17%     158.000us      17.556us             9  \n",
      "                                       aten::contiguous         0.18%       7.023us         2.70%     103.386us     103.386us      11.000us         0.29%     109.000us     109.000us             1  \n",
      "                                            aten::clone         0.34%      13.207us         2.40%      92.025us      92.025us      19.000us         0.50%      98.000us      98.000us             1  \n",
      "                                            aten::empty         1.33%      50.849us         1.33%      50.849us       5.085us      87.000us         2.28%      87.000us       8.700us            10  \n",
      "                                             aten::view         0.72%      27.721us         0.72%      27.721us       3.080us      61.000us         1.60%      61.000us       6.778us             9  \n",
      "                                            aten::copy_         0.86%      33.122us         1.28%      48.952us      48.952us      55.000us         1.44%      55.000us      55.000us             1  \n",
      "                                       aten::empty_like         0.23%       8.686us         0.54%      20.559us      20.559us      13.000us         0.34%      24.000us      24.000us             1  \n",
      "                                        cudaEventRecord        26.92%       1.032ms        26.92%       1.032ms       2.234us       0.000us         0.00%       0.000us       0.000us           462  \n",
      "                                       cudaLaunchKernel         6.42%     246.179us         6.42%     246.179us       4.319us       0.000us         0.00%       0.000us       0.000us            57  \n",
      "                                 cudaDeviceGetAttribute         0.37%      13.996us         0.37%      13.996us       0.350us       0.000us         0.00%       0.000us       0.000us            40  \n",
      "                                  cudaFuncGetAttributes         0.88%      33.672us         0.88%      33.672us       3.367us       0.000us         0.00%       0.000us       0.000us            10  \n",
      "cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         1.01%      38.882us         1.01%      38.882us       0.486us       0.000us         0.00%       0.000us       0.000us            80  \n",
      "                                         cuLaunchKernel         1.00%      38.293us         1.00%      38.293us       4.255us       0.000us         0.00%       0.000us       0.000us             9  \n",
      "                                  cudaDeviceSynchronize         0.19%       7.264us         0.19%       7.264us       7.264us       0.000us         0.00%       0.000us       0.000us             1  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 3.834ms\n",
      "Self CUDA time total: 3.823ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_device = 'cuda') as prof:\n",
    "    sequences, scores = beam_search(log_probs, beam_size)\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afcac3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22aa42a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
