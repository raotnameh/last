{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1b33bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a =torch.ones(2,5,1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "631a7a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.sum(dim=1).long().squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec75c9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4bb72df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0816, 0.3557, 0.3862, 0.5614, 0.7836, 0.3444],\n",
      "         [0.8075, 0.5739, 0.2482, 0.2364, 0.2070, 0.5204],\n",
      "         [0.5498, 0.2703, 0.3211, 0.2806, 0.4379, 0.0161]]])\n",
      "torch.Size([1, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example input\n",
    "x = torch.rand(1,3,6)\n",
    "\n",
    "# Duplicate along the time (T) dimension\n",
    "x_duplicated = x.repeat_interleave(1, dim=1)  # Repeat each timestep 2 times\n",
    "\n",
    "print(x_duplicated)\n",
    "print(x_duplicated.shape)  # (1, 6, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0816, 0.3557, 0.3862, 0.5614, 0.7836, 0.3444],\n",
       "         [0.8075, 0.5739, 0.2482, 0.2364, 0.2070, 0.5204],\n",
       "         [0.5498, 0.2703, 0.3211, 0.2806, 0.4379, 0.0161]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4620f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1714eefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word to character ratio: 0.18955613922824477\n",
      "Character to word ratio: 5.3258137107501025\n"
     ]
    }
   ],
   "source": [
    "with open(\"/raid/home/rajivratn/hemant_rajivratn/last/data/txt/train.wrd\", \"r\") as f:\n",
    "        sentences = f.readlines()\n",
    "sentences = [s.strip() for s in sentences if len(s.strip()) > 0]\n",
    "\n",
    "import numpy as np\n",
    "# word to character ratio \n",
    "word_to_char_ratio = np.mean([len(sentence.split()) / len(sentence) for sentence in sentences])\n",
    "print(\"Word to character ratio:\", word_to_char_ratio)\n",
    "\n",
    "# character to word ratio\n",
    "char_to_word_ratio = np.mean([len(sentence) / len(sentence.split()) for sentence in sentences])\n",
    "print(\"Character to word ratio:\", char_to_word_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1af1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33ed9f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REAL Word to character ratio for logs_0: 0.1884, 5.3519\n",
      "PREDICTED Word to character ratio for logs_0: 0.2047, 5.2488\n",
      "\n",
      "REAL Word to character ratio for logs_0.001: 0.1884, 5.3506\n",
      "PREDICTED Word to character ratio for logs_0.001: 0.1744, 6.0407\n",
      "\n",
      "REAL Word to character ratio for logs_0.01: 0.1884, 5.3518\n",
      "PREDICTED Word to character ratio for logs_0.01: 0.1201, 8.6472\n",
      "\n",
      "REAL Word to character ratio for logs_0.1: 0.1880, 5.3590\n",
      "PREDICTED Word to character ratio for logs_0.1: 0.1014, 10.3681\n",
      "\n",
      "REAL Word to character ratio for logs_1.0: 0.1887, 5.3442\n",
      "PREDICTED Word to character ratio for logs_1.0: 0.1045, 9.9629\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "# Path to your log file\n",
    "log_file_paths = [ \"/raid/home/rajivratn/hemant_rajivratn/grpo/src/logs_0/training_2025-06-03_16-14-43.log\", \"/raid/home/rajivratn/hemant_rajivratn/grpo/src/logs_0.001/training_2025-06-03_16-09-52.log\", \"/raid/home/rajivratn/hemant_rajivratn/grpo/src/logs_0.01/training_2025-06-03_16-09-34.log\", \"/raid/home/rajivratn/hemant_rajivratn/grpo/src/logs_0.1/training_2025-06-03_15-49-43.log\", \"/raid/home/rajivratn/hemant_rajivratn/grpo/src/logs_1.0/training_2025-06-03_13-51-33.log\"]\n",
    "\n",
    "for log_file_path in log_file_paths:\n",
    "    # Read the file\n",
    "    with open(log_file_path, \"r\") as file:\n",
    "        log_data = file.read()\n",
    "\n",
    "    # Extract all lines starting with 'Predicted text: '\n",
    "    predicted_texts = re.findall(r\"Predicted text:\\s*(.*?)\\n\", log_data)\n",
    "    real_texts = re.findall(r\"Real text:\\s*(.*?)\\n\", log_data)\n",
    "\n",
    "    # Display or process extracted predicted texts\n",
    "    rlines = []\n",
    "    plines = []\n",
    "    for r,p in zip(real_texts, predicted_texts):\n",
    "        rlines.append(r)\n",
    "        plines.append(p)\n",
    "\n",
    "    rword_to_char_ratio = np.mean([len(lines.split()) / len(lines) for lines in rlines])\n",
    "    rchar_to_word_ratio = np.mean([len(lines) / len(lines.split()) for lines in rlines])\n",
    "    print(f\"REAL Word to character ratio for {log_file_path.split('/')[-2]}: {rword_to_char_ratio:.4f}, {rchar_to_word_ratio:.4f}\")\n",
    "    \n",
    "    pword_to_char_ratio = np.mean([len(lines.split()) / len(lines) for lines in plines])\n",
    "    pchar_to_word_ratio = np.mean([len(lines) / len(lines.split()) for lines in plines])\n",
    "    print(f\"PREDICTED Word to character ratio for {log_file_path.split('/')[-2]}: {pword_to_char_ratio:.4f}, {pchar_to_word_ratio:.4f}\")\n",
    "    \n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a0901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae50ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb6a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e376795b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "***** Running training *****\n",
      "  Num examples = 116,722\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 350,166\n",
      "  Number of trainable parameters = 494,032,768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='350166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    10/350166 00:45 < 549:17:44, 0.18 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0005, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0004, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0007, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0013, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0026, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(0.0027, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 50\u001b[0m\n\u001b[1;32m     41\u001b[0m trainer \u001b[38;5;241m=\u001b[39m GRPOTrainer(\n\u001b[1;32m     42\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen/Qwen2-0.5B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     43\u001b[0m     reward_funcs\u001b[38;5;241m=\u001b[39mreward_func,\n\u001b[1;32m     44\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m     45\u001b[0m     args\u001b[38;5;241m=\u001b[39mgrpo_config,  \u001b[38;5;66;03m# <-- use GRPOConfig, not TrainingArguments\u001b[39;00m\n\u001b[1;32m     46\u001b[0m )\n\u001b[1;32m     47\u001b[0m trainer\u001b[38;5;241m.\u001b[39madd_callback(KLLossLoggerCallback())\n\u001b[0;32m---> 50\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/transformers/trainer.py:2560\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2553\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2554\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2556\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2558\u001b[0m )\n\u001b[1;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2566\u001b[0m ):\n\u001b[1;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/transformers/trainer.py:3730\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mtrain):\n\u001b[1;32m   3728\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m-> 3730\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   3732\u001b[0m     loss_mb \u001b[38;5;241m=\u001b[39m smp_forward_backward(model, inputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps)\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/trl/extras/profiling.py:96\u001b[0m, in \u001b[0;36mprofiling_decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m profiling_context(\u001b[38;5;28mself\u001b[39m, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m):\n\u001b[0;32m---> 96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/trl/trainer/grpo_trainer.py:972\u001b[0m, in \u001b[0;36mGRPOTrainer._prepare_inputs\u001b[0;34m(self, generation_batch)\u001b[0m\n\u001b[1;32m    969\u001b[0m generate_every \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msteps_per_generation \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_iterations\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step \u001b[38;5;241m%\u001b[39m generate_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffered_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;66;03m# self._buffered_inputs=None can occur when resuming from a checkpoint\u001b[39;00m\n\u001b[0;32m--> 972\u001b[0m     generation_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_and_score_completions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    973\u001b[0m     generation_batch \u001b[38;5;241m=\u001b[39m shuffle_tensor_dict(generation_batch)\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffered_inputs \u001b[38;5;241m=\u001b[39m split_tensor_dict(generation_batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msteps_per_generation)\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/trl/trainer/grpo_trainer.py:1092\u001b[0m, in \u001b[0;36mGRPOTrainer._generate_and_score_completions\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m unwrap_model_for_generation(\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator, gather_deepspeed3_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mds3_gather_for_generation\n\u001b[1;32m   1086\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m unwrapped_model:\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m (\n\u001b[1;32m   1088\u001b[0m         FSDP\u001b[38;5;241m.\u001b[39msummon_full_params(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped, recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1089\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fsdp_enabled\n\u001b[1;32m   1090\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m nullcontext()\n\u001b[1;32m   1091\u001b[0m     ):\n\u001b[0;32m-> 1092\u001b[0m         prompt_completion_ids \u001b[38;5;241m=\u001b[39m \u001b[43munwrapped_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprompt_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;66;03m# Compute prompt length and extract completion ids\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m prompt_length \u001b[38;5;241m=\u001b[39m prompt_ids\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/transformers/generation/utils.py:2465\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[0m\n\u001b[1;32m   2457\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2458\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2459\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2460\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2461\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2462\u001b[0m     )\n\u001b[1;32m   2464\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2465\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2466\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2470\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2472\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2473\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2475\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2476\u001b[0m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[1;32m   2477\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2478\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2479\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2480\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2481\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2482\u001b[0m     )\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/transformers/generation/utils.py:3434\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3432\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3434\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   3436\u001b[0m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[1;32m   3437\u001b[0m model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_model_kwargs_for_generation(\n\u001b[1;32m   3438\u001b[0m     outputs,\n\u001b[1;32m   3439\u001b[0m     model_kwargs,\n\u001b[1;32m   3440\u001b[0m     is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   3441\u001b[0m )\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py:823\u001b[0m, in \u001b[0;36mQwen2ForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    819\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m    820\u001b[0m )\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/transformers/utils/generic.py:965\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    962\u001b[0m     set_attribute_for_modules(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_top_level_module\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    964\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 965\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_requested_to_return_tuple \u001b[38;5;129;01mor\u001b[39;00m (is_configured_to_return_tuple \u001b[38;5;129;01mand\u001b[39;00m is_top_level_module):\n\u001b[1;32m    967\u001b[0m         output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py:549\u001b[0m, in \u001b[0;36mQwen2Model.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    538\u001b[0m         partial(decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs),\n\u001b[1;32m    539\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m         position_embeddings,\n\u001b[1;32m    547\u001b[0m     )\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 549\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py:277\u001b[0m, in \u001b[0;36mQwen2DecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n\u001b[1;32m    276\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 277\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost_attention_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[1;32m    279\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/raid/home/rajivratn/anaconda3/envs/grpo/lib/python3.9/site-packages/transformers/models/qwen2/modeling_qwen2.py:224\u001b[0m, in \u001b[0;36mQwen2RMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    222\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    223\u001b[0m variance \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 224\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(\u001b[43mvariance\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariance_epsilon\u001b[49m)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "from trl import GRPOTrainer, GRPOConfig\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "import logging\n",
    "\n",
    "class KLLossLoggerCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            # The logs dict often contains loss and other metrics\n",
    "            # Assuming KL loss is named 'kl_loss' in logs (check trainer code)\n",
    "            kl_loss = logs.get('kl_loss')\n",
    "            if kl_loss is not None:\n",
    "                logging.info(f\"Step {state.global_step} KL loss: {kl_loss}\")\n",
    "\n",
    "# Dataset\n",
    "dataset = load_dataset(\"trl-lib/tldr\", split=\"train\")\n",
    "\n",
    "# Reward function\n",
    "def reward_func(completions, **kwargs):\n",
    "    return [float(len(set(c))) for c in completions]\n",
    "\n",
    "# Use GRPOConfig instead of TrainingArguments\n",
    "grpo_config = GRPOConfig(\n",
    "    per_device_train_batch_size=2,\n",
    "    logging_steps=1,\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./logs\",      # This enables saving logs for TensorBoard\n",
    "    report_to=[\"tensorboard\"], # Enable TensorBoard logs\n",
    "    num_generations=2,\n",
    "    log_level=\"info\",\n",
    "    logging_first_step=True,\n",
    "    log_completions=True,\n",
    "    num_completions_to_print=2,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=\"Qwen/Qwen2-0.5B-Instruct\",\n",
    "    reward_funcs=reward_func,\n",
    "    train_dataset=dataset,\n",
    "    args=grpo_config,  # <-- use GRPOConfig, not TrainingArguments\n",
    ")\n",
    "trainer.add_callback(KLLossLoggerCallback())\n",
    "\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b9e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd9df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "# Load with soundfile\n",
    "waveform_np, sample_rate = sf.read(\"/raid/home/rajivratn/hemant_rajivratn/grpo/input.wav\")\n",
    "\n",
    "def mel_spec(waveform):\n",
    "    waveform = torch.from_numpy(waveform).float().unsqueeze(0)\n",
    "\n",
    "    # Set hop length for 50Hz frame rate\n",
    "    target_frame_rate = 50\n",
    "    hop_length = int(sample_rate / target_frame_rate)  # 320 if sr=16k\n",
    "    n_fft = 1024\n",
    "    n_mels = 80\n",
    "\n",
    "    # Mel-spectrogram transform\n",
    "    mel_spec_transform = torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        power=2.0,\n",
    "        center=True,\n",
    "    )\n",
    "\n",
    "    # Compute mel and log-mel\n",
    "    mel_spec = mel_spec_transform(waveform)  # (channels, n_mels, time)\n",
    "    log_mel_spec = torch.log(mel_spec + 1e-6)\n",
    "\n",
    "    print(f\"log-mel shape: {log_mel_spec.shape}\")\n",
    "    print(f\"Each second corresponds to {target_frame_rate} frames\")\n",
    "    # Plotting the first channel (if stereo)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.imshow(log_mel_spec[0].cpu().numpy(), aspect='auto', origin='lower',\n",
    "               interpolation='none')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.xlabel('Frames (time)')\n",
    "    plt.ylabel('Mel bins')\n",
    "    plt.title('Log-Mel Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return log_mel_spec # [1, 80, 296]\n",
    "\n",
    "\n",
    "mel_spec(waveform_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989eac3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "94480 / 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fcfd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32cadd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/raid/home/rajivratn/hemant_rajivratn/last/data/txt/train.wrd\", \"r\") as f:\n",
    "    sentences = f.readlines()\n",
    "sentences = [s for s in sentences if len(s) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e029c041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading /raid/home/rajivratn/hemant_rajivratn/grpo/ngram/charlm/5.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import kenlm\n",
    "\n",
    "# Load the model (binary format loads faster)\n",
    "model = kenlm.Model('/raid/home/rajivratn/hemant_rajivratn/grpo/ngram/charlm/5.arpa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9aaa6690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: T H I S | I S | A | T E S T, Score: -0.46006283936677156\n",
      "sentence: T E T S E X K U R V T A M A E A N U S O L I O D | E Z | I A S E H P S I Y U R A | D I | E I M S K G L O | E T | E I | O E | E | U H S H I | N E | E B | E D B S O T L N L N O R | W | T H N O L O | T | H | T N A C W | E T | H | T N V L E | T O T O T O P T | P O | N | A I O A S A U N E | E S I | N A R | T | E D A L A C | A O E P D U E R S N E | E M O E R | O | E O | S H | R E S H I A | I U Y E N I E P M S L ' E P | N W | E D M U | N | P G R | R | T | E D E D C T | E H | M G L | L N L E | E T O L E O | O D I S | A E I | D R N K, Score: -1.0007251530378662\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sentence to score\n",
    "sentence = [\"this is a test\", \"TETSEXKURVTAMAEANUSOLIOD EZ IASEHPSIYURA DI EIMSKGLO ET EI OE E UHSHI NE EB EDBSOTLNLNOR W THNOLO T H TNACW ET H TNVLE TOTOTOPT PO N AIOASAUNE ESI NAR T EDALAC AOEPDUERSNE EMOER O EO SH RESHIA IUYENIEPMSL'EP NW EDMU N PGR R T EDEDCT EH MGL LNLE ETOLEO ODIS AEI DRNK\"]\n",
    "sentence = [i.replace(\" \", \"|\").upper() for i in sentence]\n",
    "sentence = [\" \".join(i) for i in sentence]\n",
    "\n",
    "for s in sentence:\n",
    "    # Score (log10 probability)\n",
    "    score = model.score(s, bos=False, eos=False) / len(s)\n",
    "    print(f\"sentence: {s}, Score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c5de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7f5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3deaa50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6175f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d8a5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"123\", \"123\"]\n",
    "tokenizer(sentences, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f0fc79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b192d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "char_counter = Counter(\n",
    "            [char for sentence in [\" hello world \"] for char in sentence if len(char) > 0]\n",
    "        )\n",
    "char_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928dd7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "            char: count / sum(char_counter.values())\n",
    "            for char, count in char_counter.items()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf71c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "\n",
    "# Define vocab (index 0 is blank)\n",
    "vocab = ['_', 'a', 'b', 'c']\n",
    "blank_id = 0\n",
    "\n",
    "# Example model output (index sequence)\n",
    "output = torch.tensor([1, 1, 0, 2, 2, 0, 2, 2, 3, 3, 0])\n",
    "\n",
    "# Step 1: Collapse consecutive repeats\n",
    "# Create a mask to keep only non-duplicate consecutive elements\n",
    "mask = torch.ones_like(output, dtype=torch.bool)\n",
    "mask[1:] = output[1:] != output[:-1]\n",
    "collapsed = output[mask]\n",
    "print(collapsed)\n",
    "# Step 2: Remove blanks (i.e., tokens with index 0)\n",
    "final = collapsed[collapsed != blank_id]\n",
    "print(final)\n",
    "# Step 3: Convert indices to characters using vocab\n",
    "decoded_string = ''.join(vocab[i] for i in final.tolist())\n",
    "\n",
    "print(\"Decoded string:\", decoded_string)  #  'bbc'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a97b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c4ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "c = np.array(['a','b','c','d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed94b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ccf8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[filtered[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ca1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ClapProcessor, ClapModel\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "# Load model and processor\n",
    "processor = ClapProcessor.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "model = ClapModel.from_pretrained(\"laion/clap-htsat-unfused\")\n",
    "\n",
    "# Load and preprocess audio\n",
    "def load_audio(path):\n",
    "    waveform, sr = torchaudio.load(path)\n",
    "    if sr != 48000:\n",
    "        resampler = torchaudio.transforms.Resample(sr, 48000)\n",
    "        waveform = resampler(waveform)\n",
    "    return waveform\n",
    "\n",
    "audio_path = \"/raid/home/rajivratn/hemant_rajivratn/librispeech/data/train/audio/train-clean-100_126791_298_53.wav\"\n",
    "audio = load_audio(audio_path)\n",
    "\n",
    "# CLAP expects mono\n",
    "if audio.shape[0] > 1:\n",
    "    audio = torch.mean(audio, dim=0, keepdim=True)\n",
    "\n",
    "# Pad or truncate to 10s (CLAP expects 480000 samples)\n",
    "audio = torch.nn.functional.pad(audio, (0, max(0, 480000 - audio.shape[1])))[:, :480000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6c2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"SPEAK I BEG WITHOUT DREAD OF MY DISPLEASURE SAID FRANCES RETURNING THE GOOD HUMORED SMILE OF THE TROOPER WITH THE ARCHNESS NATURAL TO HER OWN SWEET FACE THE ODORS OF YOUR KITCHEN THEN CRIED LAWTON BLUNTLY FORBID MY QUITTING THE DOMAINS UNTIL I QUALIFY MYSELF TO SPEAK WITH MORE CERTAINTY CONCERNING THE FATNESS OF THE LAND\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c39091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process audio and text\n",
    "texts = [\"hello how are you\", \"this is a dog barking\", \"there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with there they say is no debt and there are a girl with\", \"speak i beg without dread of my displeasure said frances returning the good humored smile of the trooper with the archness natural to her own sweet face the odors of your kitchen then cried lawton bluntly forbid my quitting the domains until i qualify myself to speak with more certainty concerning the fatness of the land\"]\n",
    "inputs = processor(audios=audio.squeeze().numpy(), text=texts, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    audio_embeds = outputs.audio_embeds\n",
    "    text_embeds = outputs.text_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize embeddings\n",
    "audio_embeds = torch.nn.functional.normalize(audio_embeds, dim=-1)\n",
    "text_embeds = torch.nn.functional.normalize(text_embeds, dim=-1)\n",
    "\n",
    "# Cosine similarity\n",
    "similarities = torch.matmul(audio_embeds, text_embeds.T).squeeze(0)\n",
    "\n",
    "# Print ranked results\n",
    "for text, score in sorted(zip(texts, similarities), key=lambda x: -x[1]):\n",
    "    print(f\"{text:<30} -> Similarity: {score.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cd7248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a570bd4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591dc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ea89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "model = kenlm.Model(\"/raid/home/rajivratn/hemant_rajivratn/grpo/3-gram.pruned.1e-7.arpa.gz\")\n",
    "\n",
    "sentence = \"this is a test\".upper()\n",
    "print(sentence)\n",
    "\n",
    "# Each tuple means this word had log10-prob logp given the previous context; ng_len is the n-gram order (e.g. 3 means a trigram was used), and oov marks out-of-vocabulary\n",
    "for (logp, ng_len, oov) in model.full_scores(sentence, bos=False, eos=False):\n",
    "    print(logp, ng_len, oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ac99ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigram(sentences):\n",
    "    for s in sentences:\n",
    "        log10p = [model.score(w, bos=False, eos=False) for w in sentence.split() if model.vocab_index(w) != 0]\n",
    "\n",
    "unigram([sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf230ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_unigram_char_probs(sentences):\n",
    "    # Flatten to a list of characters\n",
    "    chars = [char for sentence in sentences for char in sentence.strip()]\n",
    "    \n",
    "    # Count frequency of each character\n",
    "    char_counts = Counter(chars)\n",
    "    total_chars = sum(char_counts.values())\n",
    "\n",
    "    # Convert to probabilities\n",
    "    char_probs = {char: count / total_chars for char, count in char_counts.items()}\n",
    "    \n",
    "    return char_probs, chars\n",
    "\n",
    "# Example usage\n",
    "sentences = [\n",
    "    'THANK YOU AGAIN MISTER DEVANT HE SAID...',\n",
    "    'FOR WEEKS IT NEVER CAME TO MY TURN...',\n",
    "    'ONE MAN WON PAST ME INDEED DARTING...'\n",
    "]\n",
    "\n",
    "char_probs, chars = get_unigram_char_probs(sentences)\n",
    "\n",
    "# Print sorted for readability\n",
    "for char, prob in sorted(char_probs.items()):\n",
    "    print(f\"'{char}': {prob:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac18c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/raid/home/rajivratn/hemant_rajivratn/last/data/txt/train_norm.txt\", \"r\") as f:\n",
    "    out = [i for i in f.readlines() if len(i.strip()) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def preprocess_char_lm(sentences):\n",
    "    \"\"\"Prep a list of sentences for char-level n-gram LM training.\"\"\"\n",
    "    preprocessed = []\n",
    "    for s in tqdm(sentences):\n",
    "        s = s.strip().replace(\" \", \"|\")\n",
    "        chars = list(s)\n",
    "        line = \"<s> \" + \" \".join(chars) + \" </s>\"\n",
    "        preprocessed.append(line)\n",
    "    return preprocessed\n",
    "\n",
    "char_lm_lines = preprocess_char_lm(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05e7951",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"char_lm_input.txt\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in char_lm_lines:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"Saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5a042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "@torch.jit.script\n",
    "def beam_search(log_probs: torch.Tensor, beam_size: int):\n",
    "    \"\"\"\n",
    "    Performs beam search on a tensor of log probabilities.\n",
    "\n",
    "    Args:\n",
    "        log_probs (torch.Tensor): Tensor of shape (b, t, v) containing log probabilities.\n",
    "        beam_size (int): Number of beams to keep at each time step.\n",
    "\n",
    "    Returns:\n",
    "        sequences (torch.Tensor): Tensor of shape (b, beam_size, t) containing the top sequences.\n",
    "        scores (torch.Tensor): Tensor of shape (b, beam_size) containing the scores of the top sequences.\n",
    "    \"\"\"\n",
    "    \n",
    "    b, t, v = log_probs.size()\n",
    "    \n",
    "    initial_beam_size = min(beam_size, v) # At the very first step (time step 0), we can't have more beams than the vocabulary size. This line ensures that the initial number of beams considered doesn't exceed the number of possible first tokens.\n",
    "\n",
    "    topk_scores, topk_indices = torch.topk(log_probs[:, 0, :], initial_beam_size, dim=-1) # Returns the k largest elements of the given input tensor along a given dimension\n",
    "    sequences = topk_indices.unsqueeze(-1)  # (b, initial_beam_size, 1)\n",
    "    scores = topk_scores  # (b, initial_beam_size)\n",
    "\n",
    "    for step in range(1, t):\n",
    "        # Expand the current sequences with all possible next tokens\n",
    "        current_log_probs = log_probs[:, step, :].unsqueeze(1)  # (b, 1, v)\n",
    "        expanded_scores = scores.unsqueeze(-1) + current_log_probs  # (b, beam_size, v)\n",
    "        flat_scores = expanded_scores.view(b, -1)  # (b, beam_size * v)\n",
    "\n",
    "        # Select the top-k scores and their corresponding indices\n",
    "        topk_flat_scores, topk_indices = flat_scores.topk(beam_size, dim=-1)  # (b, beam_size)\n",
    "        beam_indices = topk_indices // v  # Indices of sequences to expand\n",
    "        token_indices = topk_indices % v  # New tokens to append\n",
    "\n",
    "        # Gather the sequences to expand and append the new tokens\n",
    "        sequences = torch.gather(sequences, 1, beam_indices.unsqueeze(-1).expand(-1, -1, sequences.size(-1)))\n",
    "        sequences = torch.cat([sequences, token_indices.unsqueeze(-1)], dim=-1)  # (b, beam_size, step+1)\n",
    "\n",
    "        # Update the scores\n",
    "        scores = topk_flat_scores\n",
    "\n",
    "    return sequences, scores.unsqueeze(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "sequence_length = 5\n",
    "vocab_size = 3\n",
    "beam_size = 2\n",
    "\n",
    "# Simulate log probabilities\n",
    "log_probs = torch.randn(batch_size, sequence_length, vocab_size).log_softmax(dim=-1)\n",
    "device = torch.device('cpu')\n",
    "log_probs = log_probs.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs[1,3:,:] = -float(\"1000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c28fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a06a75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform beam search\n",
    "sequences, scores = beam_search(log_probs, beam_size)\n",
    "\n",
    "print(\"Top sequences:\", sequences) # bsz, beamsize,seq_len\n",
    "print(\"Scores:\", scores) # bsz, beamsize,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences.shape, scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_probs = torch.gather(log_probs, 2, sequences.transpose(1,2)).transpose(1,2) # bsz, beamsize, T\n",
    "path_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fefdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = scores.mean(dim=1, keepdim=True)\n",
    "std = scores.std(dim=1, keepdim=True)\n",
    "\n",
    "scores = (scores - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeda04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_probs*scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd9336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences # bsz,beam,T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed129f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using PyTorch\n",
    "import torch\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "vocab = [' ', \"'\", 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '?']\n",
    "vocab = np.array(vocab)\n",
    "\n",
    "\n",
    "# Precompile regex to remove blanks and collapse repeats\n",
    "blank_char = re.escape('?')  # adjust if blank differs\n",
    "remove_blanks = re.compile(blank_char)\n",
    "collapse_repeats = re.compile(r'(.)\\1+')\n",
    "\n",
    "# Convert token sequences to strings using regex merge\n",
    "def decode(arr, vocab):\n",
    "    raw = [collapse_repeats.sub(r'\\1', remove_blanks.sub('', ''.join(vocab[row]))) for row in arr]\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846d4700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert token sequences to strings using regex merge\n",
    "def decode(arr, vocab):\n",
    "    raw = [collapse_repeats.sub(r'\\1', remove_blanks.sub('', ''.join(vocab[row]))) for row in arr]\n",
    "    return raw\n",
    "\n",
    "sentences = decode(sequences[0].cpu(), vocab)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dd92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences[0], vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = sequences[1,:,:]\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2657461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vocab_arr = np.array(vocab)\n",
    "\n",
    "decoded = [''.join(vocab_arr[row]) for row in arr]\n",
    "print(decoded)  # ['abc', 'cba']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288be618",
   "metadata": {},
   "outputs": [],
   "source": [
    "[collapse_repeats.sub(r'\\1', remove_blanks.sub('', ''.join(vocab[row]))) for row in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90407d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[''.join(vocab[row]) for row in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc135d86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode(arr, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ec8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'-'.join(vocab[np.array(arr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b57304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: vocab and array of indices\n",
    "vocab = ['a', 'b', 'c', 'd', 'e']\n",
    "vocab_arr = np.array(vocab)  # shape (V,)\n",
    "arr = np.array([\n",
    "    [0, 1, 2],\n",
    "    [2, 3, 4],\n",
    "])  # shape (2, 3)\n",
    "\n",
    "# Step 2: index vocab\n",
    "char_matrix = vocab_arr[arr]  # shape (2, 3), dtype='<U1'\n",
    "\n",
    "# Step 3: vectorized join  this is the key step!\n",
    "joined = np.char.join('-', char_matrix)  # shape (2,), dtype='<U5' etc.\n",
    "\n",
    "print(joined)  # Output: ['a-b-c' 'c-d-e']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8502bc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = ['-'.join(vocab[row]) for row in arr]\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395b675c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5436f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633e287",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arr = torch.tensor([[0, 1, 2], [2, 1, 0]])\n",
    "decoded = [''.join(vocab_arr[row]) for row in arr.numpy()]\n",
    "print(decoded)  # ['abc', 'cba']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [decode_one(seq, vocab) for seq in sequences[0,:,:].cpu().numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8511fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b99a96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee00fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) move to CPU & to plain Python list of lists\n",
    "sentences = []\n",
    "for b in range(sequences.shape[0]):\n",
    "    print(b)\n",
    "    rows = sequences[b].cpu().tolist() # beam,T\n",
    "    decoded_beams = [ctc_merge_string( ''.join(idx2char[i] for i in row) ) for row in rows]\n",
    "    sentences.append(decoded_beams)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _decode_one( seq):\n",
    "    chars = [vocab[i] for i in seq]\n",
    "    raw = ''.join(chars)\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c276fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a152fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_decode_one(sequences[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afcac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1.  beamctc decoder\n",
    "2. \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22aa42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6669dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
