{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d8823bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/home/rajivratn/anaconda3/envs/langspeech/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "# --- Config ---\n",
    "model_dir = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "device = torch.device(\"cuda:5\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 1\n",
    "learning_rate = 5e-5\n",
    "max_length = 512\n",
    "gradient_accumulation_steps = 4\n",
    "save_steps = 1000\n",
    "log_interval = 10  # Log every 10 iterations\n",
    "output_dir = \"charllama-finetuned\"  # Directory to save checkpoints\n",
    "log_dir = os.path.join(\"runs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# --- Dataset class ---\n",
    "class CharDataset(Dataset):\n",
    "    def __init__(self, file_path, tokenizer, max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.sentences = self._load_and_preprocess(file_path)\n",
    "\n",
    "    def _load_and_preprocess(self, file_path):\n",
    "        with open(file_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        return [line.strip().upper() for line in lines if len(line.strip()) > 10]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence = self.sentences[idx]\n",
    "        sentence = \" \".join(sentence)\n",
    "        tokens = self.tokenizer(\n",
    "                        sentence,\n",
    "                        max_length=max_length,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt',\n",
    "                        add_special_tokens=False  # <-- This disables special tokens\n",
    "                    )\n",
    "        input_ids = tokens['input_ids'].squeeze(0)\n",
    "        attention_mask = tokens['attention_mask'].squeeze(0)\n",
    "        labels = input_ids.clone()\n",
    "        labels[attention_mask == 0] = -100\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "# --- Load tokenizer ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0bc861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 1235.81M\n",
      "Trainable parameters: 384.31M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3604935/3188201710.py:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# --- Load model, optimizer, scheduler, and scaler from checkpoint (if available) ---\n",
    "checkpoint_path = None  # Set to the checkpoint directory if you want to resume training\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dir).to(device)\n",
    "# Count trainable parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {num_params / 1e6:.2f}M\")\n",
    "\n",
    "# Freeze all parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the last 2 transformer layers\n",
    "transformer_layers = model.model.layers  # Access the transformer block list\n",
    "num_layers = len(transformer_layers)\n",
    "\n",
    "for i in range(num_layers - 2, num_layers):\n",
    "    for param in transformer_layers[i].parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Also unfreeze the final language model head (optional but often useful)\n",
    "for param in model.lm_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.model.norm.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "\n",
    "# Count trainable parameters\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable parameters: {num_params / 1e6:.2f}M\")\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    lr=learning_rate\n",
    ")\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,  # Will be updated if loading from checkpoint\n",
    "    num_training_steps=1 # Initialize with a non-zero value to avoid the check if loading\n",
    ")\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "global_step = 0\n",
    "start_epoch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8712d4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from scratch.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(output_dir, exist_ok=True)\n",
    "print(\"Starting training from scratch.\")\n",
    "train_dataset_temp = CharDataset(\"/raid/home/rajivratn/hemant_rajivratn/last/data/txt/train.wrd\", tokenizer, max_length)\n",
    "scheduler = transformers.get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=len(DataLoader(train_dataset_temp, batch_size=batch_size)) // 10,\n",
    "    num_training_steps=len(DataLoader(train_dataset_temp, batch_size=batch_size)) * num_epochs // gradient_accumulation_steps\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca84928c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 0/35132 [00:00<?, ?it/s]/tmp/ipykernel_3604935/3480990317.py:21: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Epoch 1/1:   0%|          | 80/35132 [00:20<2:18:57,  4.20it/s, loss=2.2199, lr=0.000000, step=21]"
     ]
    }
   ],
   "source": [
    "# --- Create dataset and dataloader ---\n",
    "train_file_path = \"/raid/home/rajivratn/hemant_rajivratn/last/data/txt/train_norm.txt\"\n",
    "dataset = CharDataset(train_file_path, tokenizer, max_length)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "loss_fct = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "# --- Training Loop ---\n",
    "model.zero_grad()\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), initial=global_step % len(dataloader) if start_epoch == epoch else 0, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    for step, batch in progress_bar:\n",
    "        if start_epoch == epoch and step < global_step % len(dataloader):\n",
    "            continue  # Skip steps already done in the previous run\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            )\n",
    "            logits = outputs.logits[:, :-1, :].contiguous()\n",
    "            labels = labels[:, 1:].contiguous()\n",
    "            loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
    "\n",
    "        loss = loss / gradient_accumulation_steps\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "            global_step += 1\n",
    "\n",
    "            # Log loss and learning rate to TensorBoard every log_interval steps\n",
    "            if global_step % log_interval == 0:\n",
    "                writer.add_scalar('loss/step', loss.item() * gradient_accumulation_steps, global_step)\n",
    "                writer.add_scalar('learning_rate', scheduler.get_last_lr()[0], global_step)\n",
    "\n",
    "            if global_step % save_steps == 0:\n",
    "                checkpoint_dir = os.path.join(output_dir, f\"checkpoint\")\n",
    "                os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "                model.save_pretrained(checkpoint_dir)\n",
    "                tokenizer.save_pretrained(checkpoint_dir)\n",
    "                torch.save(optimizer.state_dict(), os.path.join(checkpoint_dir, 'optimizer.pt'))\n",
    "                torch.save(scheduler.state_dict(), os.path.join(checkpoint_dir, 'scheduler.pt'))\n",
    "                torch.save(scaler.state_dict(), os.path.join(checkpoint_dir, 'scaler.pt'))\n",
    "                print(f\"Checkpoint saved at step {global_step} to {checkpoint_dir}\")\n",
    "\n",
    "        total_loss += loss.item() * gradient_accumulation_steps\n",
    "        progress_bar.set_postfix({\"loss\": f\"{total_loss / (step + 1):.4f}\", \"lr\": f\"{scheduler.get_last_lr()[0]:.6f}\", \"step\": global_step + 1})\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch + 1} - Average Loss: {avg_loss:.4f}\")\n",
    "    writer.add_scalar('loss/epoch', avg_loss, epoch + 1)\n",
    "\n",
    "# --- Save the final trained model ---\n",
    "final_output_dir = os.path.join(output_dir, \"final-model\")\n",
    "os.makedirs(final_output_dir, exist_ok=True)\n",
    "model.save_pretrained(final_output_dir)\n",
    "tokenizer.save_pretrained(final_output_dir)\n",
    "print(f\"Final model saved to {final_output_dir}\")\n",
    "\n",
    "# --- Close TensorBoard writer ---\n",
    "writer.close()\n",
    "print(f\"TensorBoard logs saved to {log_dir}\")\n",
    "print(\"To view TensorBoard logs, run: `tensorboard --logdir runs` from your terminal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c89ffb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    46,    452,    256,    362,    445,    445,    256,    393,    507,\n",
       "           445,    358,    350,    358,    356,    362,    445,    256,    362,\n",
       "           452,    423,    256,    445,    358,    350,    469,    432,    362,\n",
       "           432,    816,    256,   1229,    549,    469,    328,    350,    358,\n",
       "           507,    452,    328,    256,    350,    473,    469,    256,    386,\n",
       "           358,    452,    358,    328,    350,    469,    432,    256,    468,\n",
       "           362,    328,    256,    350,    473,    469,    256,    507,    432,\n",
       "           362,    356,    445,    469,    256,    507,    435,    256,    473,\n",
       "           358,    328,    256,    507,    468,    452,    256,    356,    358,\n",
       "           432,    356,    445,    469,    256,    358,    350,    256,    468,\n",
       "           362,    328,    256,    393,    507,    393,    549,    445,    362,\n",
       "           432,    445,    816,    256,    432,    469,    386,    362,    432,\n",
       "           735,    469,    423,    256,    423,    549,    432,    358,    452,\n",
       "           480,    256,    386,    362,    452,    816,    256,    816,    469,\n",
       "           362,    432,    328,    256,    350,    473,    362,    350,    256,\n",
       "           362,    452,    256,    469,    386,    358,    452,    469,    452,\n",
       "           350,    256,    423,    358,    328,    328,    469,    452,    350,\n",
       "           358,    452,    480,    256,    386,    358,    452,    358,    328,\n",
       "           350,    469,    432,    256,    473,    362,    423,    256,    507,\n",
       "           452,    445,    816,    256,    350,    507,    256,    386,    362,\n",
       "           735,    469,    256,    473,    358,    328,    256,    328,    507,\n",
       "           452,    256,    362,    452,    256,    362,    350,    350,    507,\n",
       "           432,    452,    469,    816,    256,    507,    432,    256,    362,\n",
       "           256,    393,    473,    816,    328,    358,    356,    358,    362,\n",
       "           452, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "        128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1954e528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O N   A L L   P O L I T I C A L   A N D   L I T E R A R Y   Q U E S T I O N S   T H E   M I N I S T E R   W A S   T H E   O R A C L E   O F   H I S   O W N   C I R C L E   I T   W A S   P O P U L A R L Y   R E M A R K E D   D U R I N G   M A N Y   Y E A R S   T H A T   A N   E M I N E N T   D I S S E N T I N G   M I N I S T E R   H A D   O N L Y   T O   M A K E   H I S   S O N   A N   A T T O R N E Y   O R   A   P H Y S I C I A N'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f34d784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ON ALL POLITICAL AND LITERARY QUESTIONS THE MINISTER WAS THE ORACLE OF HIS OWN CIRCLE IT WAS POPULARLY REMARKED DURING MANY YEARS THAT AN EMINENT DISSENTING MINISTER HAD ONLY TO MAKE HIS SON AN ATTORNEY OR A PHYSICIAN'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa3679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b1b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcefbab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d551ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8907cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "       \n",
    "model_name=\"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "# Initialize the model and tokenizer \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "# Freeze LLM parameters\n",
    "# Freeze all parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the last 2 transformer layers\n",
    "transformer_layers = model.model.layers  # Access the transformer block list\n",
    "num_layers = len(transformer_layers)\n",
    "\n",
    "for i in range(num_layers - 2, num_layers):\n",
    "    for param in transformer_layers[i].parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Also unfreeze the final language model head (optional but often useful)\n",
    "for param in model.lm_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.model.norm.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "    \n",
    "# device = torch.device(\"cpu\")\n",
    "# model.to(device)\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccde7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de2eee2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight True\n",
      "model.layers.0.self_attn.q_proj.weight False\n",
      "model.layers.0.self_attn.k_proj.weight False\n",
      "model.layers.0.self_attn.v_proj.weight False\n",
      "model.layers.0.self_attn.o_proj.weight False\n",
      "model.layers.0.mlp.gate_proj.weight False\n",
      "model.layers.0.mlp.up_proj.weight False\n",
      "model.layers.0.mlp.down_proj.weight False\n",
      "model.layers.0.input_layernorm.weight False\n",
      "model.layers.0.post_attention_layernorm.weight False\n",
      "model.layers.1.self_attn.q_proj.weight False\n",
      "model.layers.1.self_attn.k_proj.weight False\n",
      "model.layers.1.self_attn.v_proj.weight False\n",
      "model.layers.1.self_attn.o_proj.weight False\n",
      "model.layers.1.mlp.gate_proj.weight False\n",
      "model.layers.1.mlp.up_proj.weight False\n",
      "model.layers.1.mlp.down_proj.weight False\n",
      "model.layers.1.input_layernorm.weight False\n",
      "model.layers.1.post_attention_layernorm.weight False\n",
      "model.layers.2.self_attn.q_proj.weight False\n",
      "model.layers.2.self_attn.k_proj.weight False\n",
      "model.layers.2.self_attn.v_proj.weight False\n",
      "model.layers.2.self_attn.o_proj.weight False\n",
      "model.layers.2.mlp.gate_proj.weight False\n",
      "model.layers.2.mlp.up_proj.weight False\n",
      "model.layers.2.mlp.down_proj.weight False\n",
      "model.layers.2.input_layernorm.weight False\n",
      "model.layers.2.post_attention_layernorm.weight False\n",
      "model.layers.3.self_attn.q_proj.weight False\n",
      "model.layers.3.self_attn.k_proj.weight False\n",
      "model.layers.3.self_attn.v_proj.weight False\n",
      "model.layers.3.self_attn.o_proj.weight False\n",
      "model.layers.3.mlp.gate_proj.weight False\n",
      "model.layers.3.mlp.up_proj.weight False\n",
      "model.layers.3.mlp.down_proj.weight False\n",
      "model.layers.3.input_layernorm.weight False\n",
      "model.layers.3.post_attention_layernorm.weight False\n",
      "model.layers.4.self_attn.q_proj.weight False\n",
      "model.layers.4.self_attn.k_proj.weight False\n",
      "model.layers.4.self_attn.v_proj.weight False\n",
      "model.layers.4.self_attn.o_proj.weight False\n",
      "model.layers.4.mlp.gate_proj.weight False\n",
      "model.layers.4.mlp.up_proj.weight False\n",
      "model.layers.4.mlp.down_proj.weight False\n",
      "model.layers.4.input_layernorm.weight False\n",
      "model.layers.4.post_attention_layernorm.weight False\n",
      "model.layers.5.self_attn.q_proj.weight False\n",
      "model.layers.5.self_attn.k_proj.weight False\n",
      "model.layers.5.self_attn.v_proj.weight False\n",
      "model.layers.5.self_attn.o_proj.weight False\n",
      "model.layers.5.mlp.gate_proj.weight False\n",
      "model.layers.5.mlp.up_proj.weight False\n",
      "model.layers.5.mlp.down_proj.weight False\n",
      "model.layers.5.input_layernorm.weight False\n",
      "model.layers.5.post_attention_layernorm.weight False\n",
      "model.layers.6.self_attn.q_proj.weight False\n",
      "model.layers.6.self_attn.k_proj.weight False\n",
      "model.layers.6.self_attn.v_proj.weight False\n",
      "model.layers.6.self_attn.o_proj.weight False\n",
      "model.layers.6.mlp.gate_proj.weight False\n",
      "model.layers.6.mlp.up_proj.weight False\n",
      "model.layers.6.mlp.down_proj.weight False\n",
      "model.layers.6.input_layernorm.weight False\n",
      "model.layers.6.post_attention_layernorm.weight False\n",
      "model.layers.7.self_attn.q_proj.weight False\n",
      "model.layers.7.self_attn.k_proj.weight False\n",
      "model.layers.7.self_attn.v_proj.weight False\n",
      "model.layers.7.self_attn.o_proj.weight False\n",
      "model.layers.7.mlp.gate_proj.weight False\n",
      "model.layers.7.mlp.up_proj.weight False\n",
      "model.layers.7.mlp.down_proj.weight False\n",
      "model.layers.7.input_layernorm.weight False\n",
      "model.layers.7.post_attention_layernorm.weight False\n",
      "model.layers.8.self_attn.q_proj.weight False\n",
      "model.layers.8.self_attn.k_proj.weight False\n",
      "model.layers.8.self_attn.v_proj.weight False\n",
      "model.layers.8.self_attn.o_proj.weight False\n",
      "model.layers.8.mlp.gate_proj.weight False\n",
      "model.layers.8.mlp.up_proj.weight False\n",
      "model.layers.8.mlp.down_proj.weight False\n",
      "model.layers.8.input_layernorm.weight False\n",
      "model.layers.8.post_attention_layernorm.weight False\n",
      "model.layers.9.self_attn.q_proj.weight False\n",
      "model.layers.9.self_attn.k_proj.weight False\n",
      "model.layers.9.self_attn.v_proj.weight False\n",
      "model.layers.9.self_attn.o_proj.weight False\n",
      "model.layers.9.mlp.gate_proj.weight False\n",
      "model.layers.9.mlp.up_proj.weight False\n",
      "model.layers.9.mlp.down_proj.weight False\n",
      "model.layers.9.input_layernorm.weight False\n",
      "model.layers.9.post_attention_layernorm.weight False\n",
      "model.layers.10.self_attn.q_proj.weight False\n",
      "model.layers.10.self_attn.k_proj.weight False\n",
      "model.layers.10.self_attn.v_proj.weight False\n",
      "model.layers.10.self_attn.o_proj.weight False\n",
      "model.layers.10.mlp.gate_proj.weight False\n",
      "model.layers.10.mlp.up_proj.weight False\n",
      "model.layers.10.mlp.down_proj.weight False\n",
      "model.layers.10.input_layernorm.weight False\n",
      "model.layers.10.post_attention_layernorm.weight False\n",
      "model.layers.11.self_attn.q_proj.weight False\n",
      "model.layers.11.self_attn.k_proj.weight False\n",
      "model.layers.11.self_attn.v_proj.weight False\n",
      "model.layers.11.self_attn.o_proj.weight False\n",
      "model.layers.11.mlp.gate_proj.weight False\n",
      "model.layers.11.mlp.up_proj.weight False\n",
      "model.layers.11.mlp.down_proj.weight False\n",
      "model.layers.11.input_layernorm.weight False\n",
      "model.layers.11.post_attention_layernorm.weight False\n",
      "model.layers.12.self_attn.q_proj.weight False\n",
      "model.layers.12.self_attn.k_proj.weight False\n",
      "model.layers.12.self_attn.v_proj.weight False\n",
      "model.layers.12.self_attn.o_proj.weight False\n",
      "model.layers.12.mlp.gate_proj.weight False\n",
      "model.layers.12.mlp.up_proj.weight False\n",
      "model.layers.12.mlp.down_proj.weight False\n",
      "model.layers.12.input_layernorm.weight False\n",
      "model.layers.12.post_attention_layernorm.weight False\n",
      "model.layers.13.self_attn.q_proj.weight False\n",
      "model.layers.13.self_attn.k_proj.weight False\n",
      "model.layers.13.self_attn.v_proj.weight False\n",
      "model.layers.13.self_attn.o_proj.weight False\n",
      "model.layers.13.mlp.gate_proj.weight False\n",
      "model.layers.13.mlp.up_proj.weight False\n",
      "model.layers.13.mlp.down_proj.weight False\n",
      "model.layers.13.input_layernorm.weight False\n",
      "model.layers.13.post_attention_layernorm.weight False\n",
      "model.layers.14.self_attn.q_proj.weight True\n",
      "model.layers.14.self_attn.k_proj.weight True\n",
      "model.layers.14.self_attn.v_proj.weight True\n",
      "model.layers.14.self_attn.o_proj.weight True\n",
      "model.layers.14.mlp.gate_proj.weight True\n",
      "model.layers.14.mlp.up_proj.weight True\n",
      "model.layers.14.mlp.down_proj.weight True\n",
      "model.layers.14.input_layernorm.weight True\n",
      "model.layers.14.post_attention_layernorm.weight True\n",
      "model.layers.15.self_attn.q_proj.weight True\n",
      "model.layers.15.self_attn.k_proj.weight True\n",
      "model.layers.15.self_attn.v_proj.weight True\n",
      "model.layers.15.self_attn.o_proj.weight True\n",
      "model.layers.15.mlp.gate_proj.weight True\n",
      "model.layers.15.mlp.up_proj.weight True\n",
      "model.layers.15.mlp.down_proj.weight True\n",
      "model.layers.15.input_layernorm.weight True\n",
      "model.layers.15.post_attention_layernorm.weight True\n",
      "model.norm.weight True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f81404b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7fda699f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['H E M A N T   I S   M Y   N A M E',\n",
       " 'H E E E M M M A N N N N T   I I I I S   M M M M Y   N   N A A A M E   E E',\n",
       " 'D R N O T   T L   K T C R N T   S T   R C T   S   C   C D R   C   T   D G T   R M   R T C E T P C R   R T   T   D C   G E S D T   R E S D E   R   D R   G C E C G C O R G T   E F L E R C   N C G K E   E D E S   E D C D   L T K T   R   D E R T   T S   F   D N S L   G R K T S N G   R K R D G C T R L S   C G   N S T G T   R T   C N T R   L T E R T E P R D R L S H S   D E L   O   T   R T S   T N   T   G L   E T G T G S   E T   G C G   D L S   T   G D   G R G S T L S K S T   T C   T   R D R E T D   T   L   T O L G S N L T R E G T E   S R T G R   S R E   C N   G T   N K R   R L G R   C G   D T   G   R D G   C P   D E S C T G R T   C E D T   S L T R S   T   G   G L G   G   R G   T P   D   L E   V D V   E T   L R U   C R   C S E   G T L   T   L T   R T D T G   C R T S   R   D T S C   D T   N E']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts = [\n",
    "    \"Hemant is my name\",\n",
    "    \"Heeemmmannnnt iiiis mmmmy n naaame ee\",\n",
    "    \"DRNOT TL KTCRNT ST RCT S C CDR C T DGT RM RTCETPCR RT T DC GESDT RESDE R DR GCECGCORGT EFLERC NCGKE EDES EDCD LTKT R DERT TS F DNSL GRKTSNG RKRDGCTRLS CG NSTGT RT CNTR LTERTEPRDRLSHS DEL O T RTS TN T GL ETGTGS ET GCG DLS T GD GRGSTLSKST TC T RDRETD T L TOLGSNLTREGTE SRTGR SRE CN GT NKR RLGR CG DT G RDG CP DESCTGRT CEDT SLTRS T G GLG G RG TP D LE VDV ET LRU CR CSE GTL T LT RTDTG CRTS R DTSC DT NE\"\n",
    "]\n",
    "\n",
    "input_texts = [\" \".join(i.upper()) for i in input_texts ]\n",
    "input_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "943164bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[    39,    469,    386,    362,    452,    350,    256,    358,    328,\n",
       "             256,    386,    816,    256,    452,    362,    386,    469, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009, 128009,\n",
       "          128009, 128009, 128009, 128009]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])},\n",
       " 'H E M A N T   I S   M Y   N A M E')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o  = tokenizer(\n",
    "            input_texts[0],\n",
    "            max_length=256,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "            add_special_tokens=False  # <-- This disables special tokens\n",
    "        )\n",
    "o, tokenizer.decode(o['input_ids'][0].tolist() , skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb927924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(\"HEMANT IS MY NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c4b7cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([    39,    469,    386,    362,    452,    350,    256,    358,    328, 256,    386,    816,    256,    452,    362,    386,    469])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a1c457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langspeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
