{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator(\n",
      "  (disc_layers): ModuleList(\n",
      "    (0): Conv1dBlock(\n",
      "      (layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): Conv1d(2048, 256, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (1): GELU(approximate='none')\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Conv1dBlock(\n",
      "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (conv): Conv1d(256, 256, kernel_size=(9,), stride=(1,))\n",
      "    )\n",
      "    (4): GELU(approximate='none')\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): CausalTransformer(\n",
      "    (pos_enc): SinusoidalPositionalEncoding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proj): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "Number of parameters: 1.909249\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "class Conv1dBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1, stride=1, groups=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.causal_padding = (kernel_size - 1) * dilation\n",
    "        self.layernorm = nn.LayerNorm(in_channels)  # Normalize over channel dim\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size, \n",
    "            stride=stride, \n",
    "            dilation=dilation, \n",
    "            padding=0,\n",
    "            groups=groups,\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x, padding_mask=None):\n",
    "        # x is expected to be of shape (batch, time, channels)\n",
    "        if padding_mask is not None:\n",
    "            x = x.masked_fill(padding_mask, 0)\n",
    "        \n",
    "        x = self.layernorm(x)\n",
    "        \n",
    "        x = x.transpose(1, 2)\n",
    "        # Apply causal (left) padding: (padding_left, padding_right)\n",
    "        x = F.pad(x, (self.causal_padding, 0))\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1024):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create matrix of shape (max_len, d_model)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)  # (max_len, 1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))  # (d_model//2)\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # even indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # odd indices\n",
    "\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)  # register as buffer (not a parameter)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch, seq_len, d_model)\n",
    "        Returns:\n",
    "            Tensor of shape (batch, seq_len, d_model) with positional encoding added\n",
    "        \"\"\"\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "    \n",
    "class CausalTransformer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers=2, dim_feedforward=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.pos_enc = SinusoidalPositionalEncoding(d_model, max_len=2048)\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=d_model,\n",
    "                nhead=nhead,\n",
    "                dim_feedforward=dim_feedforward,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "            )\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, padding_mask=None):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len, d_model)\n",
    "        padding_mask: (batch, seq_len) - True for padding tokens\n",
    "        \"\"\"\n",
    "        bsz, seq_len, _ = x.size()\n",
    "        device = x.device\n",
    "\n",
    "        # Add sinusoidal positional encoding\n",
    "        x = self.pos_enc(x)\n",
    "\n",
    "        # Causal mask: prevent attending to future positions\n",
    "        causal_mask = torch.triu(torch.ones(seq_len, seq_len, device=device), diagonal=1).bool()\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(\n",
    "                src=x,\n",
    "                src_mask=causal_mask,\n",
    "                src_key_padding_mask=padding_mask\n",
    "            )\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_channels=256, hidden_dim=256, kernel_size=9, groups=1):\n",
    "        super().__init__()\n",
    "\n",
    "        torch.backends.cuda.enable_flash_sdp(False)\n",
    "        torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "        torch.backends.cuda.enable_math_sdp(True)\n",
    "        \n",
    "        self.disc_layers = nn.ModuleList([\n",
    "            Conv1dBlock(in_channels, hidden_dim, kernel_size=1, groups=groups),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            Conv1dBlock(hidden_dim, hidden_dim, kernel_size),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "        ])\n",
    "        # self.proj = Conv1dBlock(hidden_dim, 1, kernel_size)\n",
    "        \n",
    "        \n",
    "        self.decoder = CausalTransformer(d_model=hidden_dim, nhead=8, num_layers=1)\n",
    "        self.proj = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x, padding_mask=None):\n",
    "        \"\"\"\n",
    "        x: (batch, time, channels)\n",
    "        padding_mask: (batch, time, 1) where True indicates a padded timestep.\n",
    "        \"\"\"\n",
    "        \n",
    "        for layer in self.disc_layers:\n",
    "            if isinstance(layer, Conv1dBlock):\n",
    "                x = layer(x, padding_mask)  # Pass padding_mask only to Conv1dBlock\n",
    "            else:\n",
    "                x = layer(x)  # GELU & Dropout don't need padding_mask\n",
    "        \n",
    "        # x = x.masked_fill(padding_mask, 0)\n",
    "        # # Compute mean pooling over valid timesteps\n",
    "        # valid_counts = (~padding_mask).sum(dim=1).clamp(min=1).float()\n",
    "        # x_mean = x.sum(dim=1) / valid_counts  # (batch, channels)\n",
    "        # x_mean = x_mean.unsqueeze(1) # (batch, 1, channels)\n",
    "        \n",
    "        # x_mean = self.proj(x_mean) # (batch, 1, 1)\n",
    "        # return x_mean.squeeze(1).squeeze(1)  # (batch,)\n",
    "        \n",
    "        \n",
    "        x = self.decoder(x, padding_mask.squeeze(-1))  # (batch, time, hidden_dim), (batch, time)\n",
    "        x = x[:,0,:]  # (batch, hidden_dim)\n",
    "        x = self.proj(x)  # (batch, hidden_dim) -> (batch, 1)\n",
    "        x = x.squeeze(-1)\n",
    "        return x\n",
    "        \n",
    "    \n",
    "discriminator = Discriminator(in_channels=2048)\n",
    "print(discriminator)\n",
    "# calculate the parameters\n",
    "num_params = sum(p.numel() for p in discriminator.parameters())\n",
    "print(f\"Number of parameters: {num_params / 1e6}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "last",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
