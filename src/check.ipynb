{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 1, 2, 1, 1],\n",
       "        [2, 2, 2, 2, 2],\n",
       "        [2, 2, 1, 2, 2],\n",
       "        [1, 2, 1, 2, 2],\n",
       "        [1, 2, 2, 1, 2]], device='cuda:0')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Sample tensor of shape (32, 243) on GPU\n",
    "tensor = torch.randint(1, 3, (5, 5), device='cuda:0')  # Example tensor\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_tensor = torch.zeros((5, 2), device='cuda:0')  # Example tensor\n",
    "zeros_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1., 2., 1., 1., 0., 0.],\n",
       "        [2., 2., 2., 2., 2., 0., 0.],\n",
       "        [2., 2., 1., 2., 2., 0., 0.],\n",
       "        [1., 2., 1., 2., 2., 0., 0.],\n",
       "        [1., 2., 2., 1., 2., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.cat((tensor, zeros_tensor), dim=1)  # Concatenate along the second dimensiont\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "\n",
    "class Tokenizer(nn.Module):\n",
    "    def __init__(self, num_codebooks, save_dir=\"histogram_frames\"):\n",
    "        super(Tokenizer, self).__init__()\n",
    "        self.frame_count = 0  \n",
    "        self.save_dir = save_dir\n",
    "        self.num_codebooks = num_codebooks\n",
    "        self.codebook_usage = torch.zeros(self.num_codebooks)\n",
    "\n",
    "    def randomly_keep_one_until_zero(self, tensor):\n",
    "        dtype = tensor.dtype\n",
    "        device = tensor.device\n",
    "        result = []\n",
    "        chosen_indices = []\n",
    "\n",
    "        for row_idx, row in enumerate(tensor):\n",
    "            filtered_row = []\n",
    "            row_indices = []\n",
    "            i = 0\n",
    "\n",
    "            while i < len(row):\n",
    "                value = row[i].item()\n",
    "                \n",
    "                # Stop processing when zero is encountered\n",
    "                if value == 0:\n",
    "                    break\n",
    "                \n",
    "                # Detect consecutive duplicates\n",
    "                j = i + 1\n",
    "                while j < len(row) and row[j].item() == value:\n",
    "                    j += 1\n",
    "                \n",
    "                # Randomly select one index from the range\n",
    "                random_index = random.randint(i, j - 1)\n",
    "                filtered_row.append(row[random_index].item())\n",
    "                row_indices.append(random_index)  # Track chosen index\n",
    "                \n",
    "                # Move to next unique value\n",
    "                i = j\n",
    "\n",
    "            # Add trailing zeros to match original row length\n",
    "            filtered_row.extend([0] * (row.size(0) - len(filtered_row)))\n",
    "            result.append(torch.tensor(filtered_row, dtype=dtype, device=device))\n",
    "            chosen_indices.append(row_indices)\n",
    "            # Pad chosen_indices to consistent length\n",
    "            max_len = max(len(idx_list) for idx_list in chosen_indices)\n",
    "            padded_indices = [\n",
    "                idx_list + [-1] * (max_len - len(idx_list))\n",
    "                for idx_list in chosen_indices\n",
    "            ]\n",
    "\n",
    "\n",
    "        return torch.stack(result), torch.tensor(padded_indices, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 1., 2., 1., 0., 0., 0.],\n",
      "        [2., 0., 0., 0., 0., 0., 0.],\n",
      "        [2., 1., 2., 0., 0., 0., 0.],\n",
      "        [1., 2., 1., 2., 0., 0., 0.],\n",
      "        [1., 2., 1., 2., 0., 0., 0.]], device='cuda:0') tensor([[ 0,  1,  2,  4],\n",
      "        [ 2, -1, -1, -1],\n",
      "        [ 0,  2,  3, -1],\n",
      "        [ 0,  1,  2,  3],\n",
      "        [ 0,  1,  3,  4]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_codebooks=30)\n",
    "result, indices = tokenizer.randomly_keep_one_until_zero(tensor)\n",
    "print(result, indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Tensor:\n",
      "tensor([[ 2.,  1.,  2.,  1.],\n",
      "        [ 2., -1., -1., -1.],\n",
      "        [ 2.,  1.,  2., -1.],\n",
      "        [ 1.,  2.,  1.,  2.],\n",
      "        [ 1.,  2.,  1.,  2.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Prepare result tensor\n",
    "batch_size, max_indices = indices.shape\n",
    "extracted = torch.full((batch_size, max_indices), -1.0, device=tensor.device)  # Fill with -1\n",
    "\n",
    "# Loop through each batch\n",
    "for i in range(batch_size):\n",
    "    valid_indices = indices[i][indices[i] != -1]  # Ignore invalid indices\n",
    "    if valid_indices.numel() > 0:\n",
    "        extracted[i, :valid_indices.numel()] = tensor[i, valid_indices]\n",
    "\n",
    "print(\"Extracted Tensor:\")\n",
    "print(extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 1., 2., 1., 1., 0., 0.],\n",
       "        [2., 2., 2., 2., 2., 0., 0.],\n",
       "        [2., 2., 1., 2., 2., 0., 0.],\n",
       "        [1., 2., 1., 2., 2., 0., 0.],\n",
       "        [1., 2., 2., 1., 2., 0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "last",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
