{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fairseq\n",
    "from fairseq import checkpoint_utils\n",
    "\n",
    "\n",
    "arg_overrides = {\n",
    "    \"apply_mask\": True,\n",
    "\n",
    "    \"mask_selection\": \"static\",\n",
    "    \"mask_length\": 10,\n",
    "    \"mask_other\": 0,\n",
    "    \"mask_prob\": 0.75,\n",
    "\n",
    "    \"mask_channel_selection\": \"static\",\n",
    "    \"mask_channel_length\": 64,\n",
    "    \"mask_channel_other\": 0,\n",
    "    \"mask_channel_prob\": 0.5,\n",
    "\n",
    "    \"encoder_layerdrop\": 0.0,\n",
    "    \"dropout\": 0.0,\n",
    "    \"activation_dropout\": 0.1,\n",
    "    \"attention_dropout\": 0.0,\n",
    "\n",
    "    \"feature_grad_mult\": 0.0,\n",
    "}\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, ckpt_path=\"../weights/hubert_base_ls960.pt\"):\n",
    "        super().__init__()\n",
    "\n",
    "        state = checkpoint_utils.load_checkpoint_to_cpu(ckpt_path, arg_overrides)\n",
    "    \n",
    "        model, cfg, task = fairseq.checkpoint_utils.load_model_ensemble_and_task([ckpt_path], state=state)\n",
    "    \n",
    "        model[0].remove_pretraining_modules()\n",
    "        \n",
    "        self.model = model[0]\n",
    "    \n",
    "        self.cfg = cfg\n",
    "      \n",
    "    def forward(self, source, padding_mask): \n",
    "        w2v_args = {\n",
    "            \"source\": source, # source: (B, T)\n",
    "            \"padding_mask\": padding_mask, # padding_mask: (B, T), \n",
    "            \"mask\": True and self.training,\n",
    "            \"ret_conv\": False,\n",
    "        }\n",
    "                      \n",
    "        features, x, padding_mask = self.model.extract_features(**w2v_args)\n",
    "\n",
    "        return {\n",
    "            \"cnn_out\": features,  # B x T x C\n",
    "            \"encoder_out\": x,  # B x T x C \n",
    "            \"padding_mask\": padding_mask,  # B x T\n",
    "        }\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME\n",
      "DEBUG:hydra.core.utils:Setting JobRuntime:name=utils\n",
      "DEBUG:hydra.core.utils:Setting JobRuntime:name=utils\n",
      "INFO:fairseq.tasks.hubert_pretraining:current directory is /raid/home/rajivratn/hemant_rajivratn/last/src\n",
      "INFO:fairseq.tasks.hubert_pretraining:HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': '/checkpoint/wnhsu/data/librispeech/960h/iter/250K_50hz_km100_mp0_65_v2', 'fine_tuning': False, 'labels': ['layer6.km500'], 'label_dir': None, 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n",
      "INFO:fairseq.models.hubert.hubert:HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.0, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': False, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.75, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'conv_pos_batch_norm': False, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}\n",
      "/raid/home/rajivratn/anaconda3/envs/last/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (model): HubertModel(\n",
       "    (feature_extractor): ConvFeatureExtractionModel(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "          (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "          (3): GELU(approximate='none')\n",
       "        )\n",
       "        (1-4): 4 x Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "        (5-6): 2 x Sequential(\n",
       "          (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "          (2): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)\n",
       "    (dropout_input): Dropout(p=0.1, inplace=False)\n",
       "    (dropout_features): Dropout(p=0.1, inplace=False)\n",
       "    (encoder): TransformerEncoder(\n",
       "      (pos_conv): Sequential(\n",
       "        (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (1): SamePad()\n",
       "        (2): GELU(approximate='none')\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x TransformerSentenceEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (dropout_module): FairseqDropout()\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.0, inplace=False)\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (final_proj): None\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 0, 4, 9, 5, 3, 7, 8, 6, 2],\n",
       "        [7, 2, 7, 6, 0, 7, 8, 5, 0, 7]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a int tenosr of shape b,t\n",
    "# b = 2\n",
    "# t = 10\n",
    "import torch\n",
    "x = torch.randint(0, 10, (2, 10))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3,  1,  5, 10,  6,  4,  8,  9,  7,  3],\n",
       "        [ 8,  3,  8,  7,  1,  8,  9,  6,  1,  8]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "last",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
